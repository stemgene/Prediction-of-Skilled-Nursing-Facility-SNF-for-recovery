{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HW3README_Haoyuan_Dong(1028).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stemgene/Prediction-of-Skilled-Nursing-Facility-SNF-for-recovery/blob/master/2.Tuning%20hyperparameters%20for%20Random%20Forest%20and%20SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1LpKPfRuyDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVIqtu2HuyDl",
        "colab_type": "text"
      },
      "source": [
        "## Training by classification models with given data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQBfeNNuyDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"snf_train.csv\", header=0)\n",
        "df_valid = pd.read_csv(\"snf_valid.csv\", header=0)\n",
        "df_test = pd.read_csv(\"snf_test.csv\", header=0)\n",
        "# Seprate X and y\n",
        "X_train = df_train.drop([\"SNF\"], axis=1)\n",
        "y_train = df_train['SNF']\n",
        "X_valid = df_valid.drop([\"SNF\"], axis=1)\n",
        "y_valid = df_valid['SNF']\n",
        "X_test = df_test.drop([\"SNF\"], axis=1)\n",
        "y_test = df_test['SNF']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC8g_sxzuyDo",
        "colab_type": "code",
        "outputId": "68193694-21f7-4874-cdd4-8ca9f22e72bb",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "logreg = LogisticRegression(C=1e5, solver='liblinear', multi_class='ovr')\n",
        "logreg_model = logreg.fit(X_train, y_train)\n",
        "y_lr_pred = logreg_model.predict(X_test)\n",
        "\n",
        "\n",
        "# SVM\n",
        "# Ploynomial kernel\n",
        "svclassifier_ploy = SVC(kernel='poly',degree=8)\n",
        "svclassifier_ploy.fit(X_train, y_train)\n",
        "# Gaussian Kernel\n",
        "svclassifier_rbf = SVC(kernel='rbf')\n",
        "svclassifier_rbf.fit(X_train, y_train)\n",
        "# Sigmoid Kernel\n",
        "svclassifier_sig = SVC(kernel='sigmoid')\n",
        "svclassifier_sig.fit(X_train, y_train)\n",
        "# Doin predictions\n",
        "y_ploy_pred = svclassifier_ploy.predict(X_test)\n",
        "y_rbf_pred = svclassifier_rbf.predict(X_test)\n",
        "y_sig_pred = svclassifier_sig.predict(X_test)\n",
        "\n",
        "# Decision Tree\n",
        "dtc = DecisionTreeClassifier() \n",
        "dtc.fit(X_train, y_train)\n",
        "y_dt_pred = dtc.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0gEwQkNUuyDr",
        "colab_type": "code",
        "outputId": "0712cf59-1cb8-48a2-ca65-0500cddce696",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "print(\"The Logistic Regression accuracy classification score is\", round(logreg_model.score(X_test, y_test),3))\n",
        "print(confusion_matrix(y_test, y_lr_pred))\n",
        "print(classification_report(y_test, y_lr_pred))\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_lr_pred)\n",
        "\n",
        "# SVM\n",
        "s_ploy = round(svclassifier_ploy.score(X_test, y_test), 3)\n",
        "s_rbf = round(svclassifier_rbf.score(X_test, y_test), 3)\n",
        "s_sig = round(svclassifier_sig.score(X_test, y_test), 3)\n",
        "c_ploy = confusion_matrix(y_test, y_ploy_pred)\n",
        "c_rbf = confusion_matrix(y_test, y_rbf_pred)\n",
        "c_sig = confusion_matrix(y_test, y_sig_pred)\n",
        "cr_ploy = classification_report(y_test, y_ploy_pred)\n",
        "cr_rbf = classification_report(y_test, y_rbf_pred)\n",
        "cr_sig = classification_report(y_test, y_sig_pred)\n",
        "print(\"The SVM accuracy score of different kernals are :\\nPloynomial kernel {0}\\n \\\n",
        "Gaussian Kernel: {1}\\nSigmoid Kernel: {2}\".format(s_ploy, s_rbf, s_sig))\n",
        "print(\"The SVM confusion_matrix are:\\nPloynomial kernel\\n{0}\\n \\\n",
        "Gaussian Kernel:\\n{1}\\n Sigmoid Kernel:\\n{2}\".format(c_ploy, c_rbf, c_sig))\n",
        "print(\"The SVM classification reports are:\\nPloynomial kernel\\n{0}\\n \\\n",
        "Gaussian Kernel:\\n{1}\\n Sigmoid Kernel:\\n{2}\".format(cr_ploy, cr_rbf, cr_sig))\n",
        "fpr_svm_ploy, tpr_svm_ploy, _ = roc_curve(y_test, y_ploy_pred)\n",
        "fpr_svm_rbf, tpr_svm_rbf, _ = roc_curve(y_test, y_rbf_pred)\n",
        "fpr_svm_sig, tpr_svm_sig, _ = roc_curve(y_test, y_sig_pred)\n",
        "\n",
        "#Decision Tree\n",
        "print(\"The Decision Tree accuracy classification score is\", round(dtc.score(X_test, y_test),3))\n",
        "print(confusion_matrix(y_test, y_dt_pred))\n",
        "print(classification_report(y_test, y_dt_pred, target_names=[\"0\", \"1\"]))\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_dt_pred)\n",
        "\n",
        "# Random Forest\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_test, y_test),3))\n",
        "print(confusion_matrix(y_test, y_rfc_pred))\n",
        "print(classification_report(y_test, y_rfc_pred, target_names=[\"0\", \"1\"]))\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_rfc_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Logistic Regression accuracy classification score is 0.864\n",
            "[[163  18]\n",
            " [ 30 141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       181\n",
            "           1       0.89      0.82      0.85       171\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       352\n",
            "   macro avg       0.87      0.86      0.86       352\n",
            "weighted avg       0.87      0.86      0.86       352\n",
            "\n",
            "The SVM accuracy score of different kernals are :\n",
            "Ploynomial kernel 0.812\n",
            " Gaussian Kernel: 0.807\n",
            "Sigmoid Kernel: 0.486\n",
            "The SVM confusion_matrix are:\n",
            "Ploynomial kernel\n",
            "[[152  29]\n",
            " [ 37 134]]\n",
            " Gaussian Kernel:\n",
            "[[158  23]\n",
            " [ 45 126]]\n",
            " Sigmoid Kernel:\n",
            "[[  0 181]\n",
            " [  0 171]]\n",
            "The SVM classification reports are:\n",
            "Ploynomial kernel\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       181\n",
            "           1       0.82      0.78      0.80       171\n",
            "\n",
            "   micro avg       0.81      0.81      0.81       352\n",
            "   macro avg       0.81      0.81      0.81       352\n",
            "weighted avg       0.81      0.81      0.81       352\n",
            "\n",
            " Gaussian Kernel:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82       181\n",
            "           1       0.85      0.74      0.79       171\n",
            "\n",
            "   micro avg       0.81      0.81      0.81       352\n",
            "   macro avg       0.81      0.80      0.81       352\n",
            "weighted avg       0.81      0.81      0.81       352\n",
            "\n",
            " Sigmoid Kernel:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       181\n",
            "           1       0.49      1.00      0.65       171\n",
            "\n",
            "   micro avg       0.49      0.49      0.49       352\n",
            "   macro avg       0.24      0.50      0.33       352\n",
            "weighted avg       0.24      0.49      0.32       352\n",
            "\n",
            "The Decision Tree accuracy classification score is 0.807\n",
            "[[152  29]\n",
            " [ 39 132]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       181\n",
            "           1       0.82      0.77      0.80       171\n",
            "\n",
            "   micro avg       0.81      0.81      0.81       352\n",
            "   macro avg       0.81      0.81      0.81       352\n",
            "weighted avg       0.81      0.81      0.81       352\n",
            "\n",
            "The Random Forest accuracy classification score is 0.884\n",
            "[[169  12]\n",
            " [ 29 142]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89       181\n",
            "           1       0.92      0.83      0.87       171\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       352\n",
            "   macro avg       0.89      0.88      0.88       352\n",
            "weighted avg       0.89      0.88      0.88       352\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vREfhhTuyDt",
        "colab_type": "code",
        "outputId": "6792eeaf-269d-4150-dcad-6f21b1437f19",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot([0,0], [1,1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='Logistic Regression')\n",
        "plt.plot(fpr_svm_ploy, tpr_svm_ploy, label=\"SVM with Ploynomial kernel\")\n",
        "plt.plot(fpr_svm_rbf, tpr_svm_rbf, label=\"SVM with Guassian kernel\")\n",
        "plt.plot(fpr_svm_sig, tpr_svm_sig, label=\"SVM with Sigmod kernel\")\n",
        "plt.plot(fpr_dt, tpr_dt, label=\"Decision Tree\")\n",
        "plt.plot(fpr_rf, tpr_rf, label='Random Forest')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel(\"True positive rate\")\n",
        "plt.title(\"ROC curve\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXl43FW5+D9ntmS2JDOTPWmS7p2wtdACRbgoAi6soiLLBUXFiwriAojSIgW5orjgAnIBoaLirqAsitvPlQAtFChJStu0JcsksyWzZvbz+2Mmk6TZpm3SLD2f58kzM99l5s00fd9z3lVIKVEoFAqFAkAz2wIoFAqFYu6gjIJCoVAo8iijoFAoFIo8yigoFAqFIo8yCgqFQqHIo4yCQqFQKPIoo6BQKBSKPMooKBYcQoi9QohBIURYCNErhNgshLDsd80pQoi/CiFCQoiAEOL3Qojm/a4pEULcI4R4M/deu3Kvyw/vb6RQHD6UUVAsVM6TUlqA1cAa4AtDJ4QQ64FngSeAWmAx8ArwbyHEktw1BuAvwFHAO4ES4BTAB5w4U0ILIXQz9d4KRSEoo6BY0Egpe4E/kjUOQ3wNeFRK+W0pZUhK6ZdSbgBagNty11wJNADvkVK2SikzUkq3lPIOKeXT432WEOIoIcSfhBB+IUSfEOKLueObhRBfHnHdW4UQXSNe7xVCfF4I8SoQEUJsEEL8ar/3/rYQ4ju556VCiB8IIVxCiG4hxJeFENpD/KoUCkAZBcUCRwhRD7wL2JV7bSK74v/lOJf/Ajgr9/xM4A9SynCBn2MF/gz8gezuYxnZnUahXAqcA5QBPwLeLYQoyb23FrgYeCx37Q+BVO4z1gBnAx89gM9SKCZEGQXFQuVxIUQI6ATcwJdyx+1k/+5d49zjAobiBY4JrpmIc4FeKeU3pJSx3A7k+QO4/ztSyk4p5aCUch/wEnBh7twZQFRK2SKEqCJr5D4tpYxIKd3At4BLDuCzFIoJUUZBsVC5UEppBd4KrGJY2fcDGaBmnHtqAG/uuW+CayZiEbD7oCTN0rnf68fI7h4ALmN4l9AI6AGXEGJACDEA/B9QeQifrVDkUUZBsaCRUv4d2Ax8Pfc6AjwHvH+cyy9m2OXzZ+AdQghzgR/VCSyd4FwEMI14XT2eqPu9/iXw1pz76z0MG4VOIA6USynLcj8lUsqjCpRToZgUZRQURwL3AGcJIYaCzTcDHxRCfEoIYRVC2HKB4PXAptw1PyKrgH8thFglhNAIIRxCiC8KId49zmc8CVQLIT4thCjKve9JuXPbyMYI7EKIauDTUwkspfQA/w94BNgjpWzLHXeRzZz6Ri5lViOEWCqEOP0gvheFYgzKKCgWPDkF+yiwMff6X8A7gIvIxg32kQ3Yniql3Jm7Jk422NwO/AkIAi+QdUONiRVIKUNkg9TnAb3ATuBtudM/IpvyupesQv95gaI/lpPhsf2OXwkYgFay7rBfcWCuLoViQoQasqNQKBSKIdROQaFQKBR5lFFQKBQKRR5lFBQKhUKRRxkFhUKhUOSZd823ysvLZVNT02yLoVAoFPOKrVu3eqWUFVNdN++MQlNTE1u2bJltMRQKhWJeIYTYV8h1yn2kUCgUijzKKCgUCoUijzIKCoVCocijjIJCoVAo8iijoFAoFIo8M2YUhBAPCyHcQojtE5wXQojv5IahvyqEOH6mZFEoFApFYczkTmEz2YHnE/EuYHnu52PA92dQFoVCoVAUwIzVKUgp/yGEaJrkkgvIDk+XQIsQokwIUZPrF69QKBRHNPFYnI7de2h98V+4drWj2ddPxYlO3n/dDTP6ubNZvFbH6BGEXbljY4yCEOJjZHcTNDQ0HBbhFAqFYqaQUhIJBHizs5s393XT191DuHMXCZ+LdDQMyQQinRxzn++VmVfZs2kUxDjHxh3uIKV8AHgAYO3atWoAhEKhmNOkkklCXg9dXT28+WY3blcfAY+bWL8HEfSgjYURMrPfXTqExopWU05aX0zSDGWxBNW9/Vh1gyz/9EdoeMd4Q/+ml9k0Cl1kh50PUQ/0zJIsCoVCURBSSmLhEAFPH67uXrq7evC4+gh63cQGvMjwAPp4eOyNGgMGjRUhqhCG5QiNlYzWSMiUIGkdxFwJ9Y3lOI8+lqa9A/jv+AoprxfHh6+i/Npr0RQXH5bfbzaNwu+Aa4UQPwNOAgIqnqBQKGabdCpJyOcj5HXT19NLd3cP3t4+wl4P8YAPERlAs59rJyMEGq0Bk06PRmcio68nI2sRwo7QWEFjJmQMMGByoSkNYqsuYvGyRRy94hiW25ej1+oBSPl89N15J+6nn6FoxQrq770X4zFHH9bff8aMghDip8BbgXIhRBfwJUAPIKW8H3gaeDewC4gCV82ULAqFQgG5VX4kTMjrIej14HG5cHW78Pf1EfZ7SQb8iMHgGN92VGMkri/CoNdgKy2jTKtHj5FYxkFELkVmqhEie9egLoTP5CJo7qXY4ae60cGKZcs4qvoEmkqb0GnGql0pJcEnn6Tvzv8lE4lQcf2ncHzkIwiD4TB8K6OZyeyjS6c4L4FPztTnKxSKI490KkXY7yPodRPyevD19dHb00u/u4+o30sq6EekEqPuSQktIa2FsM7CoKGWUlsjtZY0dboUNgn6RBGhwRL6kouIpapBagimICUS+E29+E37iFhforTawKKmGo5atByn/Z00lDSgEVNn/SddLnpv20T473/HeNxx1Nz5ZYqWLZupr2hK5l3rbIVCcWQipSQeiWQVvi+70u93u3H3uBjwuBns95EOBxD75atENcWEdFbCOgtRyyq0JXYsNgcNNg0rSiI0yH70/SFi/Wn6B4rxJBfR712EWxbhBiQZAsVe/CUu/KZXiJcGKK8vYdmiBk6tcOK0n0mdpS6/Uyj498lkGPjFL3Df/XVkJkPVF7+A7fLLEVrtNH5rB44yCgqFYk6QTqWI9Pvzq/ys0u/D29tH0OshNuBDJmKj70FDSGfJ/VQxaFuGrtSB2VGOo7KK6ppKjrNGacq8SXlkL/EeD35XJz5/L77eOtypRt7MrMq/X1wfxmPqxm96Dp+pB+wxauvLcVat5C2ONTjtl1FpqjxgA7A/ib17cW3YSHTLFsynrKf69tsx1Ncf0ntOF8ooKBSKw0I8GiHo9RD05JS+z0PA48bX10fI6yER7Ac5epU/qCnOKXwroeLlRK1W9KV2LI4KKqqrqakuZ4XDQn1ZEY1aP45oB7jbCb65FV93GF+rDl+8hpZUI4H0aoaaOGQ0SQKmPvpK2/GbXPhMPRgqJMtqm3DanZzjOJtV9lWUG8un9TuQqRT+zZvxfPd7CIOBmju/TOlFFx2ykZlOlFFQKBSHTCadJtzvI+j15Ff5IW9W6fe7+wj7vKTjg6PvERpC2qFVfjmh0sWEdRYMpQ5KyiuorKmmrqIUp81Evc1Ivd1EtbUIbagL3O3g2UK0ay++bQP4vIJX4zX4kw34UytJcSwAEknCNIDX2oOr+BV8ph78Jhe2SgtOxyqOdzhxOs7AaXdSWlQ6o99RrL0d1y0biL3+OpYz3071xlvRV1XO6GceDMooKBSKKYlHo4S8boK+YaUf9LgJej0MeNxEB/yQGV2MldAWExhS+kXLCJkteaVfWlFJdVU59XYzR9tM1NuNLLKZqC4tRq/VZHcMgS7wtIO7jeTLu+jv9LHDncEfq8KXasSXamQwc0z+86RhkHCpjx7jVnqK9uI39TBgctNoX0Szo5m324/D6biElbaVWAyWw/bdZRIJvN//Pr4HH0JbWkrdPd/C+o53zKndwUiUUVAojnAymTSR/v7c6j6r6Pd/nohGRt0jhYao3kpAYyaosxOyNmRdPDoL+lIHtsoKasvLWGQ3cpzNxKLcar+mrJgi3YhAqpQQ7Ab3NmhvI+NuZ6DTja8viW+wMq/8A+nzGXL9CG2aVEmIfoubvfp/4yrei8/UQ6ooxvKy5TgdTk6xn4nT4WSFbQVGnfEwfpujib78Mq4NG0ns3k3pBRdQefPn0dlssyZPISijoFAscBKxwezqPreyH8rcGToW6vch0+lR96R0xUQMVgaEmYB2MUGbhXBe6duxV2RX+YtsJtbYjCyyZ5V+XZmRYv042TNSQrAH9rblXD/tRHs68bli+AYr8KUas66f9Hmk5FBuvkRbEidWFaLP+Ao7NdvpLdpHsNiLXqtnpX1lzv9/Kc2OZpaVLcOgPfx5/eORiUZx33MP/T/6MbqaahY9+ACW006bbbEKQhkFhWIeIzMZwgP+UX787Op+OIMnHhndckEKDcliK2GdFb+w0W+pJ6TLunZCOitaq43q8jLqc8p+rc2YfW4zUWczYjJMojaGlL+7Lev68bSTdO3C74riizrwpxqyq//0mQymS/K36Y1pRHWScImHN/W7aJPb8BR3ktImMeqMOO1O1jqcOO0X4nQ4WVy6GL1GP1Nf6yER+c9/cG28lWR3N7bLLqPis59FazHPtlgFo4yCQjGHScZiw64cn4egxzPKtx/y+cikU6PukQYj8aISQjoLXv1i/DbzcAaPzoLWXEK93ZJX+ifajNTbTCyyZ1f61uIClK2UEOoFz/DKP+PeQbDHjy9qx5fMun18mfUEkhcy1P9Sq5MYKwRp+yAh4y52a1vZnt5KWD8AgFVvxelwcrb9NJwOJ06Hk0ZrI1rN7ObuF0I6EKDva18j8OvfYGhqovHHP8K0du1si3XAKKOgUMwSMpMhEhjIrejdYzJ3gl43sXBo9E1CQ8ZUQqyohKDGgbusHh/mEbn6VgzFw+6cepuJk0co/XqbiVLjAaywpYRw36iVP+52or3d+MK2vM/fl15Nf+ocUpnsewsBVocebYWkqMRPj2EP7eIVWpPbSJN1VdmKbDgdTj5gfy/NjmacDif1lvo5G4CdjOCf/kTv7beT9vfjuPpqyq/9JJqiotkW66BQRkGhmCGS8dhoRe8b9uNnV/reMat8YSgmbSpjsKiEAesy3CYjbmnMrfKtRLQmigy6fOC2wWbiLTllP3SszKQ/cMUqJYTd2ZW/Z0feCCR7d+OPlOBLNuJPNeDNLMefOpPB1LA7xGjVUbrIiN0+yICpl326N3g1s4U9kd35ayr1lTgdTq52XI3T7qTZ0UyVqWpeGoCRpLxeer98J6E//IEip5NF99+P8aijZlusQ0IZBYXiIJCZDNFgYJTvfuTzkNfDYCg4+iYh0FjKSBtLiegr6K9tojdtpDdtzK/0E5oiDDpNfpXfYDPylqE8/Zy7x2E2HLwylRIinpzS35F3/2Tc7QTDxfhSDXiTTfjlUnzpUwnEbQy5fnR6gb3WQnW1jlhJALexk11iO9ujr9Ad7s6+/yDUmmtxOpycs/xdOB1ZAzDdRWCzjZSSwBNP0PeVu5DRKBWf/jSOj3wYoZ+bcY4DQRkFhWIckok4Ia93jGsn5BvK4PGSTo5un6wxFKOx2kgaS4k4VuIrN+NKF9OdLCKktRLRmcgILXqtoLYsG7htshk5zT5C6dtMlFuK0GimYQUd9oxw+bTlH6PhdM7t04Qvswyf/G/6YxWkMll1IASUVhhx1FmorYCQxUNX0W62J1+ltb8Vd9QNYSAMDdYGjik/hotXXozT7sRpd1JWXHboss9hkj09uL50G5F//hPjmjXZBnZLlsy2WNOGMgqKIw4pJYPBwAg3zmg/ftDrYTAYGH2TEBisZWCxkTBVEypZhk+a6EkV8WaiiIDWSkJjACHQagQ1pcV5pX/qCH/+IruRSmsx2ulQ+kNEvPsp/nbwtJGMhLLZPslGfHI5Pt6HP17DYGLY120sMeCoNXNUnRmNI4nP1EOHpo1/Blpp87fhD/khBBqhYXHJYk6sPjGr/B1OVtlXYTVYp+/3mOPITIb+n/4Uzze+iQSqNmzAdtmlCM3UnVDnE8ooKBYcqURidC7+CNfO0PH9V/m6oiIMpeVIcxmx2mZCi8x4pImuZDH74gaCmuwqH7LOlBpTMfV2E405986inLun3makprQYnXYGFEXEl1v5D2f84G4jE/ETSFdnV/9yBX5xLr7E/xCImsm7fgwa7DVmmuos2OvMJMvC9Bbt5Y3Yy/zH10arv5VQZzaorRM6lpYt5b/q/yvv/19hW4FJb5r+32meEO/Yg2vjRga3bsX8lrdQvWkThvq62RZrRlBGQTGvkFIyGAoOr+o9I1w6OQMQDQyMvkkIjKU29CU2MmU1ULmSkMaCO2OkM1nEnkE9YZld5QMQh6qSIuptJhbbjJw2YqWfVfpGDLoZXB1G/WNcPnjakWEP0UwZ/pzy92nfji95Ff5IKem0ZuhXpbTSRPkSMyvrLJTVGIla/ewVu2j3P8+Tvlbae9uJdkUBMGgMrLCt4J1N78z6/+3NLLMto0g7PzNnphuZTOJ7ZDPe730PYTRS85WvUHrhBfM+QD4Zyigo5hSpZJKwzzs2RdM33F0zlRw9JEVXVITZXo7Wake/+Bh0Biv9wkxfxsibcQO7ozpi6dx/4lj2p9xSRL3NSJPdxKkj/Pn1NiO1E1XlTjdR/6hgb/4x4iaZKcq6fliBT/cWfKn/xhexE4sP/5c1lhgorzNzdJ0FR62F0poi/MZedgTb2OJvo83Xxo7WHcTT8ez1OiMrbSu5YNkF+R3AkrIlc7YIbLaJtbbSs2ED8dY2rGefTfXGDegqKmZbrBlHGQXFYWPUKn+kL3+Ebz8y0D/mPrPNjsnmwFBZR0njUUR0FnzCTG+6mL2xIvaEMsRSEpJALhRgNxuySr9mWOnX27NunroyE0bDYSyGGuwfleaZfwz3kZGarOtHrsCnPwG/vBhvtJxgyMAo10+thcVOM45aC446M+YqPZ2pPbT52vizv41WXys7d+8klcmmuFr0FlbZV3HxyotpdjTTbG+msWR+FIHNNpl4HO9938f30ENobTbqvv1tSt5x9myLddgQcr/+5XOdtWvXyi1btsy2GIpxGDnwfLwUzaDPQyoeH3WPzlCEtbwCk82RDeIWlxLWWfBhpieVde10BhJEEqN785Qa9aNW90PpmvW5VgyWollY7wwOjL/yD/ciJVnXDyvwGU7IGoFYFf5AMencLmbI9eOoM+PIrf7tdWZ0pRneGHiDtpzyb/W1siewh7TMfielRaU025vzFcDN9mbqrfUFjYJUjCb60ku4btlAYs8eSi+6iKqbbkRbtjCyqYQQW6WUU5ZYq52CoiBGDTwf01gt+zoyMHZIiqm0jJKKSsrqGihdcSzxohKCOguejInuVBH7woLOgUFC0RREh++zFOmyyr7cxPoVQ8VZOb++3UhJIa0YZopYYPyVf8gFkHX9sBxf8Tp8vAufrMUXNBMbHPZDm0oMOOrMHH28Jb/6t9eYiRKhzdfG676ttPpbaft3G/uC+5C5EZOOYgfNjmbOaDgjbwhqzDUL2sd9OEiHI3i+9S36H3sMfU0Nix56CMupb5ltsWYFZRQUwNDAc++4rRaGnifjo0ch6vQGrOUVWMsrWHTMGqQ5W4kb0Fpwp410JQx0BlN09kcZ8CbBO3yvUZ9hkR3qbUbWLbbng7hD7RlKjQdRlTvdxILjr/xDPQBZ1w9N+Iwn4dO8HZ++Hl+whGBQMDQmOO/6WTbs+nHUWTBaDfhjftp8bfzb/3da97TStqWNrnBX/uOrzdU47U7eveTdHOU4CqfdSYVp4fu0Dzfhf/4L15duJeXqxfbf/03lp69HY54/DeymG2UUjgDGG3g+ciRiyOsh3O8fd5VvdVTgqFvEomPWkDaXEdVn2yn3ZYx0DGroGojR5Y/i6xwZ/E1RpItQb8tQbzNx3KLSYaWfe7QfSlXudBMPjb/yD2ardKWEqKYKn/EUfLqP4jc14guX4fdrSaey39mQ66diqZlVOdePo95MicMIAjyDHtp8bfzH10rri620+droi/blRVhkzQ6Cee+K99Jsb2aVYxX2YvusfB1HCumBAfru+iqBxx/HsGQJjT/5Mabjj59tsWYdFVNYAIwceD5yhT+co+8hGRs9ClGr02Etr6CkvBJreQVmezlpYxlhvYV+jYXeVBGdwRRd/VE6+wfxhEbHAgxaDXVDAdwROfpDK/0KS9HcUfpDxMMjVv4jCr2Cw6vzpKYUn/kU/Lrj8GUW44s48Pn1xKLDU8WGXD/2OgvldRYcdRZs1SZ0Bi1SSnoiPbT5sv7/tlwWkC/mA0AgaCptymf/OO1OVjlWUWIoGSOuYuYI/vFZeu+4g3R/P46rP0r5xz8+bxvYFYqKKSwg4tHIsB9/ZOZOLmsn4vcj5ehRiMaSUkrKK7DV1NF4zGpM9nIypjJCegs+aaYnrmH7QJyu/ihd/YP0vhnLbRQiQASdJtuKod5m5G0rK7Ir/BGN1yqt09SKYSaIh8G7Y7TLx9MOgc78JRmNkYD1ZHzFF+MzLMtO+eovItifGuv6WZML/NZl3T9GS3aQS0Zm6Ax1stX3b1pfy67+2/xtBOLZFCit0LKkbAmn1p2a7wG00rbyiC4Cm22Sbjd9d3yZ0J/+RHFzMw0PPkCx0znbYs0p1E5hlhl/4PnoHP3EYHTUPVqdDqujIrfSr8BaXonFUU7KWEpQa8EjTfSEU3T6B4eVfjBGOjP8b60RUFM6vMofWZy1yG6iylo0M1W500kiklv579fiIfBm/hKpMRAtOx5f0Vp8rMAfq8YXMOF3p8a4foaU/tBjicOIyBm+dCbN3uDefPZPm7+Ndn87kWR2TKVeo2e5bfmoHcBy23KKdcWH/3tRjEFKSeC3j9N3113IWIzy667FcdVVCN2Rsy4udKegjMIMM3LgeX5AyojMnbDfh9xv4HmxtYSSvMKvoMRRgcVRkVX6Ogu9SR3d/XG6+gfpzCn9noFBUiOUvhBQZS0e7rmzn4snPyB9PpCIjrPyb4OBYeWP1kCi7Cj8pnX4hRNfvBZf0IrPnSYWGW5PbSox4Ki34KgdXv0PuX6GSKaT7A7sHuUC2uHfQSydDbQXa4tZYV+RNwDNjmaWli5Fr1VFYHORRFc3vbfeSuQ//8G49gRq7riDosWLZ1usw44yCoeB/MDzMY3Vhlf68f0Gnmu0Oqzl5ZTst9K3OspJmcoY0JhwRSSd/qyyH1rpd/cPkkiPNh4V1qIxyn4omDtmQPp8IBEF7xujV/6edujfR96no9GTcawkYF6LT3s0vmQ9vlApPg8EvcPZUboibVbx12Z9//u7foaIp+Ps7N+ZV/6tvlZ29u8kmcn2RjLrzayyrxq1A2gqbUKnOXJWmPMVmU7T/5PHcN9zDwKouOFz2C65ZME1sCsUZRRmGO+be/nJhs+NKcYqtljzyn4oiFtSXoHFUU7GWIYvU0R3IJ5b4UdHuXjiqdFK32E2UL9fW+WRQd3D0ophJkgOZpX//j7//r2MVP7Svoxo2Rp82mOzzd4iNnw+Df2uQdK570oIKKsyYa+d2PUzRDQZZUf/jqwByPn/dw/szheBlRhK8sVfTke2DXRDSYMqApuHxHfvxrVhI4Mvv4z5tNOo2XQb+tra2RZrVlGB5hmmd/dOUvE4p132ISoaF+cMQDmGYuOo6/ojCT70yAvsdO8jmugYda7MlK3KXVFl5YxVlaNGKNZPNSB9PpCMTbDy3wtDgXGNDhzLSFScgL/uw/gzS/BGKvD7dfj2RIlFhruZmkrTOOqM1K+0D7t+akzoxjGOoUSIdn/7qAygPYE9+SIwe7Edp8PJ6fWn50dB1ppr517GlOKAkMkkvh/8AO+996Exmaj96l2UnH+++nc9AOa51pk9gl43CMEJ51yAVjexL/mFvX5e6Qrw3uPrOaq2ZITiL3BA+nwgGQPfznFW/nuGlb/QgmMZmcpjCTRekR3rGKvC12/A1xMl+NpI108MR62ZJavL82mf9nFcP0P0x/rzin/ICHSGhjONqkxVOB3OfCdQp91JpalSKYoFxuD213Ft2EC8vR3ru95J9S23oCtfWBPfDgfKKBwkQY8bi80+qUEAaHMFEQLuuPCo+b/yT8XBu3Psyt/fsZ/yX4qsPIro0kvwsTIb9B0w4nNF6W+PjnD9hCmrMlHRUMKq9TX51X+Jo3iM62cIT9ST9/0PuYBcEVf+fJ2ljmZHM+9Z9p78IJiFNgpSMZpMLIb33nvxPfwIOrud+u99F+uZZ862WPOWGdVSQoh3At8GtMBDUsq79jvfAPwQKMtdc7OU8umZlGm6CHrclJRXTnlda0+QxeXm+WUQUnHw7dqvwndHTvnnGtMJLdiXQKWTxIr34tc48SXq8QUt+F2D+F6MjHD9hDCVxnHUWahfZc/6/msndv1ANoWwN9Kb7f+TU/6tvla8g8O9MppKmlhdsZrLVl2WNwClRaUz/OUo5hLRF1/EtWEjiX37KH3fe6m66Sa0JaoQ8FCYMU0lhNAC9wJnAV3Ai0KI30kpW0dctgH4hZTy+0KIZuBpoGmmZJpOAh43tStWTXldW2+QY+vnaJfFVCKr/EemeXp2gG/3COWvySr/ilVkVl3AgOEofMkG/OESfK4YvtfCI7J+QuiKolnXz5qKvPJ31Fkotky8o5JS0hXqotXfOmoHMBDPDsvRCA1LSpdwSu0p+VGQK20rsRgsM/wFKeYq6XAYzze/Sf9jP0VfX0/DIw9jXr9+tsVaEMzk8vVEYJeUsgNACPEz4AJgpFGQwJBZLwV6ZlCeaSOTThP2eympmHynEIwl6fQPcsm6hsMk2QSkEuDfPc7Kfzfk+u8jNGBbDBWrkKvOI2puxpdejC9chq83jm93mP5/Dbl+gggRpKzKRGVjCc5TanLZP5O7fiBbBLYvuG/UDqDd104omRsFqdGxvGw5ZzSckTcAK2wrMOqME76n4sgi/I9/4PrSbaR6e7F/8Eoqrr8ejUlViU8XM2kU6oDOEa+7gJP2u+Y24FkhxHWAGRjXESiE+BjwMYCGhllWsEC430cmnaa0omrS69pdWUXXXHOYtrPpZHaVPzLY62nP7gaGlD8C7Fnlz6pzSNic+DNLsz1++hL4u8N4t4SJR1JkJ9YEMJcaDsj1M0Qyk6RjoCMfBB6qAh5MZfswGTQGVtpX8u4l784bgGVlyzBoxw8oK45sUv39uO+6i8ATv8OwbClNP30M4+rVsy3WgmMmjcJ4y8XA3y/vAAAgAElEQVT9iyIuBTZLKb8hhFgP/EgIcbTcr5GPlPIB4AHI1inMiLQHQNDjBqCkfPI2xq092R44zbXTbBTSyax/f2Sw1z2k/If8+AJsTVnlv/JdZBxOBrTZHj/+viTerjD+14dcP1nlry/SYq81s3RNZcGunyES6QQ7B3YOu398bbzR/waJTLZ7qlFnxGl3ctHyi/IGYHHpYjUKUjElUkpCf/gDvXd8mXQwSPknPoHjmv9BY1CLh5lgJo1CF7BoxOt6xrqHPgK8E0BK+ZwQohgoB9wzKNchE/R6ACipnHyn0OoKYjcbqLROU/fFl38Mz92bzQAapfwbs8p/xTuQFU6ixhX4YtX4+lL4usP4ng/T74qSTmWVv9AIyiqNB+z6GWIwNcgO/45RO4Bd/btIyexuxKq34nQ4uXTVpfkagAZrgxoFqThgkn1uem+/nfBf/kLx0UfT8MjDFK9cOdtiLWhm0ii8CCwXQiwGuoFLgMv2u+ZN4O3AZiGEEygGPDMo07QQdGf74Fun2Cm0uUI015RMTz68lPC3r4BWD+s/ARVOEmUr8cdr8bnT+Loj+F4N4+sJE48MANkg7RjXz1CvnwKrocOJMO3+9lFpoHuCe8jkNnO2IhvNjmZOPfrU/A6g3lKvagAUh4SUksCvf03fV7+GTCSovPFG7B+88ohqYDdbzNg3LKVMCSGuBf5INt30YSnl60KI24EtUsrfAZ8DHhRCfIasa+lDch703Qh63ZhKy9AbJt4BpNIZdvSF+OD6xun5UNc2fD7BzoZN+HYuxv/3MEHvsPIf4/rJDXopxPUzxEBsILv6H7ED2Bfclz9faazE6XByVtNZ+V5AVaYqZQAU00qisxPXxluJtrRgWreOmi/fgaFxmv4fKaZkRs1urubg6f2O3TrieSsw7wahBjzuKTOPOrwREqnM9MUT2p/ir8Fr8bxipawymnf9DBV8We2FuX6G8A5684p/6LE73J0/X2uuxelwcv7S8/M7AFUEpphJZDpN/49/jPuebyM0Gqpvu42yi99/xDawmy3UXuwgCHndVDQtnfSa1p4gAM0101NMFXrln7iTn+fkC5dwwjubCr5PSklftC/bAsI/HAR2Dw6HbRpLGjmm/BguXnlx1gDYnZQVz9HaCsWCJL5zJz0bNhB75VUsp59O9abb0FdXz7ZYRyTKKBwgMpMh6HGzdO3Jk17X5gpi0GpYUjENA8B9u9nTk53Xu2T1xHEMKSVd4a4xOwB/zA9ki8AWlyzmxJoT86v/VfZVWA3WQ5dRoTgIZCKB98EH8d7/f2jNZmrvvpuSc89RLslZRBmFAyQSGCCdSk1Zo9DqCrKi2jI9g2zan6QjfjK2SgO26qyRycgM+4L7RhmAVn8roUSuCEzoWFq2lNPrT883gVthW6FGQSrmDIOvvYbrlg3E33iDknPOoeqWL6Kz22dbrCMeZRQOkKAnm3k0WUxBSklrT5AzVk3dG6kQQq/+he7Ep7AuCXHXC3fR5ssWgUVT2TGdBo2BFbYV+S6gzfZmltmWUaRd2IPIFfOTzOAgnu9+D//mzegqKqi/7z6sZ7xttsVS5FBG4QDJF65NYhQ8oTi+SOKggsyJdIJdA7uGdwDuV8gEKzgVDQ9Hv010p5+VtpVcsOyCfAbQkrIlqghMMS+IPP8Crls3ktz3JmUXX0zljTegtSr35VxCGYUDJFCAUWh1ZYPMzgLbW7zY+yJPdTyVHQU5sJNUriWFRW9hlb6MNZ71aC1JfnDpvTSVNqkiMMW8Ix0K4f76Nxj4+c/RNzTQsHkz5pP373qjmAsoo3CAhLxuiq0lYyasjeRAjIKUko3/3shAfIBjy4/lyuYr8y6gems9qR9exg8iR3P0GU0stU2e8aRQzEVCf/sbvbdtIuXxYL/qKio+dR0ao2pwOFdRRuEACXjcU/Y8anOFqCszUmqc2qXTFeqiO9zNLSfdwiWrLhl9MhZg344oGaljyZrpiU8oFIeLlN9P353/S/Cppyhavpz6734H47HHzrZYiilQRuEACXrc2GvrJ72mtSdQcDzhOddzAJxcM06K684/sXtwHUYzVC9Rw2MU8wMpJcGnnqbvzjtJh8OUX3ct5VdfjVAN7OYFqlTwAJBSEvS4Ka2ceNU+mEizxxspOJ7Q4mqh2lxNY8nYMv7U68+wL34CS9bUoDmAamWFYrZI9vbS9fFP0HPDDegXLWLxr39FxSc/qQzCPELtFA6AwVCQVCI+6RjOHX0hMrKwGQrpTJoXel/gbYveNrZYJxmjc3sfKVmsXEeKOY/MZBj45a9w3303MpWi8ubPY7/iCoRWJUXMN6Y0CkIII/BpoFFKeY0QYhmwXEr5zIxLN8cYTkeduHBtuL3F1Eahvb+dQDwwvutozz/oiByHoUhSt9J2cAIrFIeBxL592QZ2L7yA6aSTqLnjdgxzYBiW4uAoZKfwMPAacGrudQ/wS+AINApTF661uYJYi3TU26bOrmjpaQHgpJqxqXnp1ifZEz+TphMq0eqUl08x95CpFP5Hf4TnO99B6HRU33E7Ze97n2pRMc8pxCgsl1JeKoR4P4CUMiqO0H/1QgrXWl1BnDUlBcUAWlwtLCtbNrb7aCZNzyu7iWcuZOnxqimYYu4R2/EGrg0biL32GpYzzqD6S7eir5q89YtiflDIEjSRm4gmAXJDcxIzKtUcJeBxYzCaKDZbxj2fyUjaXUGcNVNXaMZSMV7qe2l811HnC3QEmtHpJIuOUr1gFHOHTCKB5zvfZc9730uyu5u6b36D+nu/pwzCAqKQncIdwB+AeiHED4HTgY/OqFRzlKDXTekku4Q3/VEiiXRB6ajbPNtIZBKsr10/5pxse5I9sZNoONqG3qACdYq5weArr+DasIH4zl2UnH8eVV/4AjqbinctNKY0ClLKZ4QQW4BTAAHcKKWc0zOUZ4rgFMN12g6gkrmlpwWd0HFC1QmjT0hJ37bXiGTezpITag9JXoViOshEo3i+/R38jz6KrqqK+vu/j/Wtb51tsRQzRCHZR89KKc8Gnhjn2BHDUI3CouZjJrym1RVEqxGsqJrafdTiauHYimMx6/ebt9D3Oh2eRjRC0nSM41DFVigOiUhLC66Nt5Ls7KTs0kuo/Nzn0FrGd58qFgYTGgUhhAEoBqqEEFayuwSAEuCIyzeLRyIkBqOTtrhocwVZUm6mWD+5yycQD9Dqa+Xjx318zDnZ9iS7YydTv8JKkUl1PlXMDulgEPfddzPwy19haGyk4dEfYj7xxNkWS3EYmGyn8Engs0Al8DrDRiEI3D/Dcs05gt5c5lHl5DUK6xZPHRh+sfdFJJKTa8cGmX3bXiSYPpHj19YdvLAKxSEQ+stfsg3sfD4cH/0I5ddei6a4eLbFUhwmJjQKUspvAd8SQnxaSnnPYZRpThIYqlGYoJp5IJqgJxArLJ7gasGkM3F0+dGjT/TvpaPLAUgWHzd50z2FYrpJ+Xz03XknwaefoWjlSurvuw/jMUdPfaNiQVFIoPkeIcQqoJmsO2no+GMzKdhcIzRFjcJQu+xCKplbXC2sq143djBO+9N0xE+ipqkYU4nqFaM4PEgpCf7+9/Td+b9kolEqrv8Ujo9+FKFX7ssjkUICzRuAs4FVwB+BdwD/Ao4ooxDwuNEVFWG0jq/0h9pbTLVT6An3sC+4j0tWXjLm3MC2f+FLfZS3rF106AIrFAWQdLlw3XYbkb//A+Nxx1Fz55cpWrZstsVSzCKF1Cl8AFgNvCSlvEIIUQP838yKNfcIetyUVlRNWMLf5gpRYS2iwjr5XOTnXc8D47TKjnjp6MjuDpasVq4jxcwiMxkGfv5z3F//BjKToeqLX8B2+eWqgZ2iIKMwKKVMCyFSuSykXmDJDMs15whOMVyn1RUsyHX0nOs5yo3lLC3bb4rajmfoiJ1ERY2WknI1lUoxc8T37MG1cSODW7ZiPmU91bffjqF+8hkhiiOHQozCy0KIMrKN8baQzT56aUalmoMEvW5qlq8Y91wilWGXO8TpKyZf4Wdkhuddz3NK7SljdhzhV/5KX/IKTlp3xGX7Kg4TMpXCv3kznu9+D1FURM2dd1J60XtUAzvFKCY1CrnGd7dJKQeAe4UQfwRKpJRHlFFIDEaJhUMTtsze5Q6TTMsp21vs7N+JP+Yf6zqKh9nTnm0npWYnKGaCWHs7ri/eQqy1FetZZ1K1cSP6SYZFKY5cJjUKUkophHgSOCH3etdhkWqOke+OOoH7qC2feTR5JXOLa4JW2bv+TMfgWsrsYK8xj3OnQnFwZBIJvN//Pr4HH0JbWkrdPfdgfcfZanegmJBC3EcvCCGOP9J2ByMJej3AxMN1Wl1BivUaFpdPXv7f4mphceliqs2j22HHXn2W7sR7WKOyjhTTSPSll3Ft3Ehi925KL7iAyps/rxrYKaakEKNwKnC1EGI3ECFb2SyllMfPqGRziMAUw3XaXEFWVlnRTjJDIZlOsrVvKxcuu3D0iVSCPdsHkGhZeoJqP6w4dDKRCO57vk3/j3+MrqaaRQ8+gOW002ZbLMU8oRCjcOHUl4yPEOKdwLcBLfCQlPKuca65GLiN7LyGV6SUlx3s580UQY8brV6PubRszDkpJa2uIO86evJhOK94XmEwNTg2nrD3n3SEj8VilVQ0TN1IT6GYjPC//03vrV8i2d2N7fLLqfjMZ9BalEtSUTiFVDTvPpg3FkJogXuBs4Au4EUhxO+klK0jrlkOfAF4i5SyXwgxJyNfQ+moQjN2JlFvMMZANDll0VqLqwWN0LCuet2o44ntf6Az/naOWl+j/LyKgyYdCND31a8R+M1vMCxeTONPfozphBOmvlGh2I9CdgoHy4nALillB4AQ4mfABUDriGuuBu6VUvYDzNU5DUGve+J4Qk9h7S1aXC0cXX40VsOI3UAmw5vbukhjYOkJNdMmr+LIIvinP9F7++2k/f04PvYxyj/5CTRFkxdRKhQTMZMT4euAzhGvu3LHRrICWCGE+LcQoiXnbhqDEOJjQogtQogtHo9nhsSdmMkK14aMwqpJjEIoEWK7d/tY11H3VjoGVmEszlC9dKxrSqGYjJTHQ9f1n6b7uk+hK6+g6Rc/p/Kzn1EGQXFIFLRTEELUA8ullH8TQhQBOillZKrbxjkmx/n85cBbgXrgn0KIo3N1EcM3SfkA8ADA2rVr93+PGSWZiBMNDEy4U2jrDdLoMGEpmvir3NK7hbRMjzEKqdefYm98HctPqkAzSZBaoRiJlJLA40/Qd9ddyMFBKj7zGRwfvko1sFNMC1PuFIQQHwZ+BzyUO9TIiClsk9AFjMyxrAd6xrnmCSllUkq5B9hB1kjMGYJTdUftCeKsntp1ZNQZOa7iuOGDUtL10k6S0siStarFgKIwkt3ddF79MVxf+AJFS5ey+PHfUv4/H1MGQTFtFOI++hRwMtn2Fkgp3yA7eGcqXgSWCyEW56a4XULWuIzkceBtAEKIcrLupI7CRD88TNYyOxxPsc8fnbKSucXVwvFVx2PQjmiH7X2DDk8jBn2a+pUqd1wxOTKTwf/jn7D7vPOJvvQSVRs20PjjH1G05IhrQ6aYYQpxH8WklImhzJhcVtGUvg4pZUoIcS3Zdtta4GEp5etCiNuBLVLK3+XOnS2EaAXSwI1SSt9B/i4zQiBfzTzWKOzoDSLl5EHmvkgfHYEOLlp+0ajjmdd/z57YOhqPs6HVz2RoRzHfiXfswbVhA4MvvYT51FOp2XQb+jo1mU8xMxRiFP4thLgJKBZCvI3smM4nC3lzKeXTwNP7Hbt1xHNJduTnZwuW+DAT9LrRaLVY7GPHbLa6QgA4J9kpPN87fqts19btxOTxLFEN8BQTIJNJfA8/gvfeexFGIzVf+QqlF16gUpcVM0ohRuEm4GNAO3A92dX9ETNPIehxY3WUo9GM7TPf2hOk1KintnTi+bUtPS3Yi+0st40IlQS62d1tR6vN0HDU1DOdFUcesdZWem7ZQLytDes73kH1hlvQVag5G4qZpxCj8G6y1cjfn2lh5iJBz8Q1Cm2uIM4a64QrNyklLa4WTqo+CY0YdhHJtqfoiJ1MwwoThuKZLBVRzDcy8Tje792L7+GH0dps1H3n25ScffZsi6U4gijEmX0xsEsI8YgQ4h25mMIRQ9DTN248IZ2RtPcGaa4pnfDejkAHnkEPJ9eOdh25t7xIJFPOkpMXT7u8ivlLdOtW9lxwIb4HH6T0ggtY+tSTyiAoDjuFtLm4IlebcA7wYeABIcQzUsprZly6WSadShIe6KdknG37Xl+EWDKDc5J22UOtskfFE6J+OvYUoREZmo4pn3aZFfOPdDiC55vfpP+xx9DX1bHoBw9hectbZlssxRFKQb4LKWVcCPEEMEg2k+hiYMEbhZDXC1KO6z7Kt7eYJMjc0tNCg7WBWktt/ph841l2x06mrslAsVnllh/phP/5L1xfupWUqxfbFVdQ+enr0ZhVAzvF7DGlURBCnEm2xuBM4N/Ao8Cc62Q6E+RbZo/jPmpzBdFpBMsqx5+hkMwkebHvRc5ZfM6o4/6t/ySQfi+rT1KuoyOZ9MAAfV+5i8ATT2BYsoTGn/wE0/FrZlsshaKgncI1wM+A66SUgzMsz5wi6M3WKJSOM7aw1RVkWaWFIt34IZbXva8TSUZGxxMSUTp2ZADJYjV284hESknoj8/Se8cdpAMBHNf8D+Uf/7jqV6SYMxQSU3jf4RBkLhL0uBFCg8U+1vff2hPk1GUTxwSecz2HQHBi9YnDBzv+Rkf0BKprBeZSpQSONJJuN3133EHoT3+muLmZhocepNjpnG2xFIpRTGgUhBB/l1KeLoToZ3Qju6HJaws+wT7ocWOxO9DqRn9N3nAcdyg+ZTyh2dFMadFwdlJw61/xps7hFOU6OqKQUhL4zW/p++pXkfE4lTd8DvuHPoTQqXRkxdxjsr/Kt+Uej9gUmWyNwtjMozZXNsg80WCdaDLKq55X+eBRHxw+mE7R8Xq2AnrJ8ZNPaVMsHBJdXfTeeiuR/zyHce0J1NxxB0WL1aJAMXeZsE5BSpnJPf2BlDI98gf4weERb3aZaLjOVEZhS98WUjI1Op7w5n/oCB2HozxNaYVxRuRVzB1kOo3/0R/Rcd75DG57heov3Urjo48qg6CY8xSyfz125Itc8dq6Ca5dMGTSaUI+77iZR609QWpKi7GbDePcma1PKNIWsaZyOJsk8vKfcCVP58R1i8a9R7FwiO/ejeuWDQxu24b5v06j5rbb0NfWTn2jQjEHmCym8HngZsAqhPAPHSYbX1jwO4Ww34fMZMZtmd3mCk06k7nF1cKayjUUaXPBZCnZs60P0LBkrepuuVCRySS+hx7Ce9/30ZhM1H7tq5Scd55qYKeYV0zW5uJrQAXwrdxjBVAupbRLKW88HMLNJvkahf2MQiyZZpcnPGG7bO+gl539O0dXMbu20TGwktLSFPZaVZi0EBnc/jp73vd+PN/+DtazzmTJ009Rev75yiAo5h2TuY+WSSl3CiF+BBw1dHDoj1xK+eoMyzarDE1cK93PKOxyh0ln5IQ7hedduVbZI+IJsVf/QHfiBFa/pUYpiQVGJhbD+73v4Xv4EXQOB/X3fg/r298+22IpFAfNZEbhZuAjwL3jnJPAf82IRHOEIaNgdYzOPpqqvUWLq4XSolJW2Vblj+3bso8MJ7HkxMYZklYxG0RffBHXho0k9u2j7P3vo/LGG9GWTD6FT6GY60xoFKSUH8k9nnb4xJk7BL1uzDY7OsPoYHKrK4jJoKXRbhpzz1Cr7BOrT0Q7NH/Bt5vdngbMpiSVjRM3z1PMH9LhMO5vfIOBn/4MfX09DY88jHn9+tkWS6GYFqZsnS2EuEgIYc09v1kI8QshxHFT3TffybbMHluj0OoKsqraikYz1g20L7iP3kjvqHhC8rWneDO+hiXHlSPGuUcxvwj//e90nHseAz/7OfYPfpAlv3tCGQTFgqKQeQq3SSlDQohTgPOAn3METF4LejxjahSklLnBOhO7jgDW1wwriTdffIM0RSw5WQ1Yn8+k+vvpvvEmOv/nGjQWM00/fYyqL9yMxjR2x6hQzGcKMQrp3OO5wH1Syl8DC7pxj8xkCHo9YzKPuvoHCcVSk8YT6ix11FvrswdCvXR0Oyg2JKldNvEwHsXcRUpJ8Omn6TjnXILPPEP5Jz7B4t/8BuPq1bMtmkIxIxRSvOYSQtwLvAs4QQhhoDBjMm8JD/jJpFNjCtdaJ6lkTmfSvOB6gbObzs5nGKVbn2ZvfC1LV1vRaBf0V7YgSfa56d20ifBf/0rx0UfT8MgjFK9cMdtiKRQzSiFG4WKyc5q/K6XsF0LUks1MWrAEPR5gbDpqmyuIELCqemzAuNXXSigZGhVP6Hr+VRLyfJasXz6zAiumFSklA7/6Fe6v3Y1MJKi86SbsV16hGtgpjggKaZ0dFkK0Am8VQrwV+KeU8pkZl2wWCU5QuNbaE2Sxw4zJMPZrG4onnFiTa5UdC9Cx14Rel6LeueAbyi4YEp2duDbeSrSlBdO6ddR8+Q4MjSqVWHHkUEj20bXAL4CG3M8vhBCfmGnBZpOhGoX93UdtvUGck8QTVtlXYS/OGoDMjj+xJ7aOxuVF6PTjD+JRzB1kOo1v82Y6zjuf2GuvUb1pEw0/3KwMguKIo5D98MeAE6WUYQAhxP8C/wHum0nBZpOgx43RWoK+uHj4WCxJp3+QS9Y1jLl+MDXIy+6Xudx5ef5Y7/MvMJh5J0tOUT7ouU7sjTdwbdhI7NVXsZx+OtWbbkNfrdqbK45MCjEKAkiOeJ3MHVuwjNcyu92VnYUwXs+jl/teJplJDscTkjE6doJWk6bxmLG1Doq5gUwk8D7wIN7/+z+0Fgu1X/86Jee8e1QrkmQySVdXF7FYbBYlVSgKp7i4mPr6evR6/UHdX4hR+BHQIoT4NVljcCHww4P6tHlCwOOmfNHoHUFrTwAYv71Fi6sFvUafb5UtO/7O7sjxLGrSYChWwcm5yOBrr+H64i3Ed+6k5NxzqfriF9DZx8Z+urq6sFqtNDU1qb5VijmPlBKfz0dXVxeLD3J2x5QxBSnl18i6kKJABLhGSvn1g/q0eYCUkpBn7E6hzRXCbjZQaR1botHiamF15WpM+mwhk+eFfxHOVKqsozlIZnCQvq9+jb0fuIR0MEj9ffdR9/W7xzUIALFYDIfDoQyCYl4ghMDhcBzSzrbQ5Pl47mcw97hgiQYGSCUT49YoNNeUjFEO/bF+2vxtnFR9UvZAJk3H61GEyNC0Rvml5xKRlufpuOBC/I88Qtn738+SJ3+P9Yy3TXmfMgiK+cSh/r0Wkn10C/BToAaoBx4TQnzhkD51DhP05lpmVw4bhVQ6w46+EM6asfUJz/fu1yq78wU6QsdSW5fGaBl/Mpvi8JIOhXDd+iXe/NCHAGjYvJmaTbehtaoGhQrF/hSyU/hvYJ2UcoOU8hbgRODKmRVr9hgvHbXDGyGRyowfT+hpwaK3cJQjO3LC/8Jf6U8vYulJSw+PwIpJCf31b3Sccy4Dv/oV9g9/mCVPPI755JNmW6wDwmKxHPJ79PT08L73vW/C8wMDA9x3330FX78/H/rQh1i8eDGrV6/muOOO4y9/+cshyTvd3H///Tz66KOzLca8oBCjsI/RAWkd0FHImwsh3imE2CGE2CWEmLAKWgjxPiGEFEKsLeR9Z5K8URhRuDY0Q2G89hYtrhbWVa9Dp9GBlHS84gNg8Vo1i3k2Sfn9dH/uBro+8Qm0ZWU0/fxnVN10IxqjcbZFmxVqa2v51a9+NeH5/Y3CVNePx9133822bdu45557uOaaaw5a1pGkUqlpeZ9rrrmGK69csGvZaaWQ1Jgo8LoQ4o9kh+ucDfxLCPFNACnlZ8e7SQihJTug5yygC3hRCPE7KWXrftdZgU8Bzx/0bzGNBDxuisxmikzDYzPbXEEMWg1LK0av2DpDnXSHu7myOffH1vc6HQOrqKqMY7Et6J6BcxYpJcEnn6LvzjtJRyKUX3ct5VdfjTAcuitv0+9fzy8Qpovm2hK+dN5RU1+4H/v27ePDH/4wHo+HiooKHnnkERoaGti9ezeXX3456XSad73rXXzzm98kHA6zd+9ezj33XLZv387rr7/OVVddRSKRIJPJ8Otf/5qNGzeye/duVq9ezVlnncUnP/nJ/PXpdJrPf/7z/PGPf0QIwdVXX8111103oWzr16+nu7s7/3rr1q189rOfJRwOU15ezubNm6mpqeHFF1/kIx/5CGazmVNPPZVnnnmG7du3s3nzZp566ilisRiRSIS//vWv3H333fziF78gHo/znve8h02bNhGJRLj44ovp6uoinU6zceNGPvCBD3DzzTfzu9/9Dp1Ox9lnn83Xv/51brvtNiwWCzfccAPbtm3jmmuuIRqNsnTpUh5++GFsNhtvfetbOemkk/jb3/7GwMAAP/jBDzjttCNvnEwhRuGp3M8QLQW+94nALillB4AQ4mfABUDrftfdQXYe9A0Fvu+MEhqnRqHVFWR5lQX9fk3t9h+9Gdz6LJ7UatavG32/4vCQ7O2l97ZNhP/f/6P4uGNp/PKXKVq+MDPArr32Wq688ko++MEP8vDDD/OpT32Kxx9/nOuvv57rr7+eSy+9lPvvv3/ce++//36uv/56Lr/8chKJBOl0mrvuuovt27ezbds2APbu3Zu//oEHHmDPnj28/PLL6HQ6/H7/pLL94Q9/4MILLwSydR7XXXcdTzzxBBUVFfz85z/nlltu4eGHH+aqq67igQce4JRTTuHmm0c7Ep577jleffVV7HY7zz77LDt37uSFF15ASsn555/PP/7xDzweD7W1tTz1VFY9BQIB/H4/v/3tb2lvb0cIwcDAwBj5rrzySr773e9y+umnc+utt7Jp0ybuueceILszeeGFF3j66afZtGkTf/7znwv7B1lAFNL76AcH+d51QOeI113AKGQPrRsAACAASURBVGeuEGINsEhK+aQQYkKjIIT4GNm0WBoaxlYUTycBdx9l1bX511JKWnuCnLGqcsy1La4WKk2VLC7J5gPv2eoCVrPkxIPLD1YcHDKTYeAXv8R9993IdJrKmz+P/YorENrpbS9yMCv6meK5557jN7/5DQBXXHEFN910U/74448/DsBll13GDTeM/W+1fv167rzzTrq6urjoootYPoXh/POf/8w111yDLtcQ0D5B+u6NN97ITTfdhNvtpqUlu3bcsWMH27dv56yzzgIgnU5TU1PDwMAAoVCIU045JS/rk08+mX+vs846K/85zz77LM8++yxr1mTrgMLhMDt37uS00/5/e+cdX/P1//HnudmRSYidYcWIxGpQlGrtJtVhtbWqqkZbRauoxmoV32+V+mrraxWtUT+jaPlSihIiFUlQK2IlZMmWfX5/3JsrkeEiQ5LzfDw+j3zG+ZzzPp97c9+fs17vzkyePJlPPvmEfv360blzZzIzMzE3N2fUqFH07duXfv365bExPj6euLg4nnvuOQCGDRvG66+/rr/+yiuvANCmTZs8jrEyUZJ6zgXNi5L6i0JogK+BSQ/LSEr5g5SyrZSybfXqJbdCWEpJQnRUHnXUqMQ0YpLT840nZMtsTkScoH2t9topYHfDCI2qTzW7VOwcVeCV0iI9LIzrw4Zz29cXc3d3XH/dSbXhw4vdITztPMo0xCFDhrBz504sLCzo2bMnf/zxR5HppZQG5b9w4UIuX77M3LlzGTZsmP7e5s2bExgYSGBgIMHBwezbtw8pZZF5Valyv/tWSsmnn36qz+Py5cu8/fbbNG7cmICAANzd3fn000+ZPXs2xsbGnDx5kldffZXt27fTq1cvA57IfczMtN2+RkZGxTaeUd4oSadwE8g92loXCM91bA20AA4JIcKA9sDOshxsTk1OIiP1Xt5BZl0MhQdnHl2IvUBcWpxe2iLl9O+EZzTFtbXqOioNZGYmMStXEerzMqn//EOtuXOov3oVpvUqxwB/x44d2bhxIwAbNmygU6dOALRv356tW7cC6K8/SGhoKK6urrz//vt4e3sTFBSEtbU1iYmJBabv0aMH3333nf5HsqjuI41GwwcffEB2djZ79+6lSZMmREVFcfz4cUDbnXT27Fns7e2xtrbWtygKsxWgZ8+erFq1iqSkJABu3bpFZGQk4eHhWFpa8uabbzJ58mT+/vtvkpKSiI+Pp0+fPixevFjfHZaDra0t9vb2HDlyBIB169bpWw0KLQZrMAghzKSUj7JwzR9oJIRwAW4Bg4AhORellPGAQ678DwGTpZSnHqGMYiUhUieZ7ZDfKTzYUsiRys5xClf9rwKNce3YpBQsrdykXrhAxPQZpIaEYNW9OzVnzsTEMX/3XkUhJSWFunXr6o8/+ugjlixZwsiRI1m4cKF+oBlg8eLFvPnmm/zrX/+ib9++2Nrmj/i3adMm1q9fj4mJCTVr1mTmzJlUrVqVZ599lhYtWtC7d2/GjRunTz9q1CguXrxIy5YtMTEx4Z133mH8+PGF2iuEYMaMGSxYsICePXvyyy+/8P777xMfH09mZiYffvghzZs3Z+XKlbzzzjtUqVKFrl27FmgraJ3S+fPn6aCLhW1lZcX69eu5fPkyU6ZMQaPRYGJiwvLly0lMTMTHx4fU1FSklHz99df58lu7dq1+oNnV1VX/7BQ6pJRFbmgHjIOB67pjD7QBdwy5tw9wEbgCTNedmw14F5D2END2YXm2adNGlhQXT/wlFw3oK29fuaQ/N/6nv2XHLw/kSzt632j58vaXtQdJUXLn+wvljx/tltnZ2SVmX2UnKy1NRn6zRJ5r3kJe6NBRxu/ZU+LP+9y5cyWaf3GTnJysfyY///yz9Pb2LmOLCicxMVG//+WXX8r333+/DK2pWBT0vQVOSQN+tw1pKSxBG595u86JnBFCPFwbQJt2D7DngXMzC0nb1ZA8S5KC1yjE5+s6SstK4+87f/NaY+3inrTg37mZ5k7L1tZKEqGEuBcYSPiMGaRfvoKN90s4fvopxvb2ZW3WU0dAQADjx49HSomdnR2rVq0qa5MKZffu3Xz55ZdkZmbi5OTEmjVrytokBYZ1H2mklNce+LHLKiF7ypSEqEhMzC0wt9LKH9xLz+JqdDJ9W9bOk+5M5BlSs1L1XUfX/M6TTW0adGpW6jZXdLJTUoj65htif1yHsaMj9b7/DivVB1wonTt35syZM2VthkEMHDiQgQMHlrUZigcwxCncEEI8A0jdgrQJaLuEKhzxUZHYOFTXv+1fuJNItswfQ8Evwg8jYUTbmm0hLYnQMCsszVJxdCm4T1TxeCQfP07EZzPJuHkTu8GDqDFpEkbFIPmgUCgKxxCn8B7aLqT6wB1gv+5chSMhOhLbGvdnD+WsXi3IKbSs3pIqJlXICNzOtTQP3DwtERrVdVQcZCUkcGfBAuJ/2YqpkxNO637Esl27sjZLoagUGLJ4LRLtzKEKT0LUHWo3bqo/Ph+RgLWZMXXt7+vlxKfFczbmLO+2fBeAG8cDyZRdcO309CxsKs8kHjjAbd9ZZMbGUu2dUTiMG4cmV1hUhUJRsjzUKQghVpBr0VkOUsrRJWJRGZGWkkxacnKehWvnIhJwq2WNJlcL4NTtU2TLbO14QmY6oZeNMDNJp7ZbtbIwu8KQGR3N7XnzSPztd8zc3Ki7fDkWLZSjVShKG0MWr+0HDui2v4AaVMBAOw/OPMrOlvyjC6yTm+MRx7E0tsS9ujtZV44QluKBS0MjjIxKch1gxUVKSfyOHYT27UfS/gNU//ADXLZsVg4hF/PmzaN58+a0bNkST09PTpw4ga+vL59+mjesSWBgIE2balu6zs7O+cTcPD09adGixWPZkCNHERYWxk8//aQ/v2bNmiLXLOTQtWtXmjRpgoeHB88++ywXLlzQnz91qsyWJhVITl2LoiA587CwsMd+vo+Lr68vixYVbyBMQ8Jxbsq1rQVeASrcNJuc4Do5TuF6bArJ6Vn5Fq2diDhB25ptMdGYEH7sBGnSCtfOFe5xlAoZ4eHcePddwj+ZiqmLCy7bt+EwZgziMQOOV0SOHz/Orl27+PvvvwkKCmL//v3Uq1ePwYMHs2nTpjxpN27cyJAh+vWhJCYmcuOGVn7s/PnzT2THsWPHgPxO4VHYsGEDZ86cYdiwYUyZMuWJ7ClJcupammRlPT0TOh/n9dYFcCpuQ8qa+Mi8wXXOFyBvEZEUQVhCmLbrKDubK+fTMTbKoF4LFXbzUZDZ2cT+9BOh/V4ixf8UjtOm4bRhPWYNnvLARL9NhdV9i3f7rdAwIwBERETg4OCg1+RxcHCgdu3aNGnSBDs7O06cuK84v3nzZgYNuj/8N2DAAL3j+Pnnnxk8eHCBZYwdO5adO3cC0L9/f0aOHAnAypUrmTFjBnD/zXjq1KkcOXIET09P/Wrh8PBwevXqRaNGjfTCfEXRpUsXLl++nO/8zz//jLu7Oy1atOCTTz7R2zBx4kR9mhUrVvDRRx8RFhZG06ZNeeedd2jevDk9evTg3r17gLbF1L59e1q2bEn//v25e/cuoG2VTJw4kS5dutC0aVP8/f31goA59cxd16SkJLp3707r1q1xd3dnx44dD61bDqGhobRq1Qp/f3+ysrKYMmUK7dq1o2XLlnz//fcAHDp0iG7dujFkyBDc3d2LrNOVK1fo1asXbdq0oXPnzvzzzz8G2/KoGBKO864QIla3xQH/A6aVmEVlREJ0JMYmplja2gHa8QSNgMaO90M25pa2yL5xitAkd5ycszA2rVzia09C2tWrXBs6lDuz52Dh6YnrrzupOrT4FU0rCj169ODGjRs0btyYsWPH8ueff+qvDR48WK8Z5OfnR7Vq1fIonr722mt6JdVff/2Vl156qcAyunTpotcCunXrFufOadXtjx49mq8Lav78+XTu3JnAwED9j3VgYCCbNm0iODiYTZs26VsnhfHrr7/i7u6e51x4eDiffPIJf/zxB4GBgfj7+7N9+3YGDRrEzp07ycjIAGD16tWMGDECgEuXLjFu3DjOnj2LnZ2dXvNp6NChfPXVVwQFBeHu7s6sWbP05ZiamnL48GHGjBmDj48Py5Yt08dwiImJyWOTubk527Zt4++//+bgwYNMmjTpoUJ+oFWGffXVV1m9ejXt2rVj5cqV2Nra4u/vj7+/PytWrODq1asAnDx5knnz5umfeWF1Gj16NEuXLiUgIIBFixYxduzYh9rxuBQ50Cy0E/Y90GoXAWRLQ55KOSQh6g7W1Wvo1yicj0igQXUrzE3u/1j5RfhRzbwaDe0acvv3f3MvuxWuHStco6lEkJmZxKxeTfTSbxHm5tT64gts+79cvlaA955f6kVaWVkREBDAkSNHOHjwIAMHDmT+/PkMHz6cQYMG0bFjR/71r3+xcePGfC2BqlWrYm9vz8aNG2natCmWlgWr93bu3JnFixdz7tw5mjVrxt27d4mIiOD48eMsWbLkoTZ2795dr1vUrFkzrl27Rr0ChAnfeOMNLCwscHZ2ZunSpXmu+fv707VrV3JUkN944w0OHz7Myy+/zPPPP8+uXbto2rQpGRkZ+rfqnPCfcF/q+mHS2N7e3gC4u7vTvHlzatWqBYCrqys3btygWrX7E0aklEybNo3Dhw+j0Wi4desWd+7coWbNwnsGoqKi8PHxYevWrTRvrh0X27dvH0FBQfpIdvHx8Vy6dAlTU1OeeeYZXFzuS+0XVKekpCSOHTuWpx5paSU3rFukU5BSSiHENillmxKz4CkhISqvZPa58ATaudzXjZdS4hfhR4faHRBAaEgCGpGJc2vlFB5G6j//EDFtOqnnzmH94gs4fvYZJjUqroBdcWNkZETXrl3p2rUr7u7urF27luHDh1OvXj2cnZ35888/2bp1q16JNDcDBw5k3LhxRUpI1KlTh7t37/L777/TpUsXYmNj2bx5M1ZWVlhbWxd6Xw45XVs5thYmOb1hwwbati1YBLmod81Ro0bxxRdf4Obmpm8lFFRuTleLIbZqNJo892s0mnx2b9iwgaioKAICAjAxMcHZ2ZnU1NQi87e1taVevXr89ddfeqcgpWTp0qX07NkzT9pDhw7lkQgvrE7Z2dnY2dnlU3wtKQwZUzgphGhd4paUMQnRkfrxhLiUdMLjU/MMMl+Ku0Rsaizta7VHRl0gNK4J9eqkYWphsNBspSM7LY3IxYu5+trrZERGUuebb6i7dKlyCI/AhQsXuHTpkv44MDAQJ6f7LyKDBw9m4sSJNGjQII+Sag79+/fn448/zveD9CAdOnRg8eLFdOnShc6dO7No0aICQ1EWJbH9JHh5efHnn38SHR1NVlYWP//8s/5t38vLixs3bvDTTz8VOi6SQ3FKY8fHx1OjRg1MTEw4ePAg165de+g9pqambN++nR9//FE/IN+zZ0+WL1+u7wK7ePEiycnJBtthY2ODi4sLW7ZsAbROpiSlTAr9RRNCGEspM4FOwDtCiCtAMtrgOVJKWWEcRUZqKvcS4vUzj/QxFHI5Bb/w++MJ0fu3kpDVlDbt1QBzYaT8fZqIGTNIDw3F9uWXcZz6CUZ2dmVtVrkjKSmJCRMmEBcXh7GxMQ0bNuSHH37QX3/99df54IMP8nXH5GBtba0ftC2Kzp07s2/fPho2bIiTkxOxsbEFOoWWLVtibGyMh4cHw4cPx76YRAlr1arFl19+Sbdu3ZBS0qdPH3x8fPTXBwwYQGBgoEHlFZc09htvvMFLL71E27Zt8fT0xM3NzaD7qlSpwq5du3jxxRepUqUKo0aNIiwsjNatWyOlpHr16vroeIayYcMG3nvvPebOnUtGRgaDBg3Cw8Pjcar1cAqTTwX+1v1tUNBmiARrSWwlIZ0dfeO6XDSgrzx35KCUUsr/HgmVTp/skpEJqfo07/3vPdnv//pJKaX0+/xzuezd/8mUhLRit6W8k5WUJCPmzJXn3JrKi926ycTDR8rapCeivElnV1T69u0r9+/fX9ZmlBtKSjpb6JzGlZJxR08PCVF5g+ucC0+gurUZ1a21/XsZWRmcunMKnwY+EH+T0GhnajsmY2FtWmY2P40kHf2L2zNnkhERgf2QIVSfOBEjqyoPv1GhKIS4uDieeeYZPDw86N69e1mbUykoyilUF0J8VNhFKeW/S8CeMkG/cK3G/e6j3OMJQdFB3Mu8R/va7Yk78T9iM53o1EYpouaQFR/PnflfEb9tG6YuLjitX4dlmwo/N0FRCtjZ2XHxYoUUZX5qKcopGAFW6FoMFZn4qEg0RsZY2VUlPTOby5GJPNe4uv66X4QfGqGhXc12XF7/F+CkBPB0JOzbx+05c8iKvUu10aNxGDcWTa4ZFAqFonxRlFOIkFLOLjVLypCEnDgKGg2XbyeQkSVpWivXorVwP1pUa4FNZiZXIhypYZ+AddXKrdyZGRXF7TlzSdy3D7OmTan//feYN1NyHwpFeeehYwqVgYSoO9joFs3kyFs018lbJKUnERwdzMgWI0n8+39EZjSivWflfROWUhK/bTt3vvoKee8e1SdOpNrIEUqvSKGoIBS1TqHSjOokREdhU10bXOdcRAJmxhqcq2kHSE/dOUWWzKJD7Q5c9dPqtTToUkJTwZ5y0m/e4saod4iYNg2zBg20AnbvjlYOQaGoQBTqFKSUsaVpSFmRmZ5O8t3YPEJ4bjWtMdZJYftF+GFuZI6HbSNCb9hQ1ToRu1qVKySkzM4mdt16Qr29uXf6NI6fzcBp/TrMXF3L2rRKQUWQzs7MzGTatGk0atQIT09PPD09mTdv3mPZ8qgYIoVtCMOHD9dLVZQWBUl0lzSVPghAYkwUoJXMllLmm3nkF+5HG8c2ZP3zF+Fpbri2ePiy/4pEWmgo1958izvz5mHZurVWwO6NNxCaSv/VKRUqinT2jBkzCA8PJzg4mMDAQI4cOaJf4VvSlIUU9oMUJv3xNFLpNRricwXXuZ2QSlxKhl4uOzIlkivxV3i54ctcPRiCpB2uz7UqS3NLDZmRQczKVUQvW4awtKTW/C+x9fEpXwJ2xcxXJ7/in9jilSx2q+rGJ88UvuK4IOnsHHKks728vACtdPbevXv113OksydPnqyXzl63bl2+MsaOHUuvXr3w9vamf//+2Nvbs2rVKlauXMnVq1eZO3cuVlZWJCUlMXXqVM6fP4+npyfDhg3D3t5eL5195coV+vfvz4IFC/Lkn5KSwooVKwgLC8NcF1rV2toaX19fQOto+vXrR0hICACLFi0iKSkJX19fVqxYwQ8//EB6ejoNGzZk3bp1WFpasmXLFmbNmoWRkRG2trYcPnyYs2fPMmLECNLT08nOzmbr1q00atRIb3tSUhI+Pj7cvXuXjIwM5s6di4+PD2FhYfTu3ZtOnTpx7Ngx6tSpw44dO7CwsKAwPvvsM27cuMGqVas4ffo0H330EUlJSTg4OLBmzRpq1apF165d6dixI3/99Rfe3t4EBwdjY2PDqVOnuH37NgsWLOC1114DYOHChWzevJm0tDT69++fR9m1tKn0r3s5EddsqztyLjyvvMWJCK1WfXvHdoSGmmJtnoSDU8WXarh39ixXBwwkavFirJ5/nga7d2H3cjlTNK0gVATp7MuXL1O/fn2DxPUe5JVXXsHf358zZ87QtGlTVq5cCcDs2bPZu3cvZ86c0ceC+O677/jggw8IDAzk1KlT+bSgipLCLkyyuiA+/vhjIiMjWb16NVlZWUyYMIFffvmFgIAARo4cyfTp0/Vp4+Li+PPPP5k0aRKgdfJHjx5l165dTJ2qjaWxb98+Ll26xMmTJwkMDCQgIIDDhw8/8rMqLip9SyEhKhKh0WBVtRrng0MBcNM5Bb8IP+zN7HGOjuTgvWa4t5IV+ocxOzWV6GX/IWbVKoyq2lNnyTfY9OhR1mY9NRT1Rl9SVCTp7BxWr17NN998Q0xMzEO7dkJCQpgxYwZxcXEkJSXphf2effZZhg8fzoABA3jllVcArajfvHnzuHnzpj54Tm5kIVLYULBkdUHMmTMHLy8vvf7UhQsXCAkJ4cUXXwS0EdRy5LhBq1Kbm5dffhmNRkOzZs30Ze/bt499+/bRqpW2FyIpKYlLly7RpUuXIp9NSaGcQnQk1tUc0BgZcS4iAadqlliZGWulssP98KrlxY2jp8nGkwbPVdx5+CkBAURMn0F6WBi2r76C48cfY2SrVm0/DZR36eyGDRty/fp1EhMTsba2ZsSIEYwYMYIWLVqQlZWFsbEx2dnZ+vS55amHDx/O9u3b8fDwYM2aNRw6dAjQtgpOnDjB7t278fT0JDAwkCFDhuDl5cXu3bvp2bMn//3vf3n++ef1eRUlhW2oDHe7du0ICAggNjaWqlWrIqWkefPmBT57oEhp7JxWipSSTz/9lHfffbfAPEob1X0UdSeP5lHTmtpWwtX4q0Tei6R9LS9CL2RjYZJCzcaOZWlqiZCVlMzt2XO49sabyIwM6q9aSe1585RDeEqoCNLZlpaWvP3224wfP17/I5yVlUV6ejoAjo6OREZGEhMTQ1paGrt27dLfm5iYSK1atcjIyGDDhg3681euXMHLy4vZs2fj4ODAjRs3CA0NxdXVlffffx9vb2+CgoLy2PE4UtgP0qtXL6ZOnUrfvn1JTEykSZMmREVF6Z1CRkYGZ8+efaQ8e/bsyapVq0hKSgK0XXiRuvDAZYFqKURFUa+5O0lpmVyLTeGV1tp/rOMR2g+5nbTht+SmNHHLRmgqVtdR0uHDRHzuS+bt29gPfYsaH3yApooSsHuaqCjS2fPmzeOzzz6jRYsWWFtbY2FhwbBhw6hduzYmJibMnDkTLy8vXFxc8khU53TXODk54e7urndIU6ZM4dKlS0gp6d69Ox4eHsyfP5/169djYmJCzZo1mTlzZh4bHlcK+0Fef/11EhMT8fb2Zs+ePfzyyy+8//77xMfHk5mZyYcffqgPsGMIPXr04Pz583To0AHQdhmuX7+eGmUUd0TkNGHKC23btpWnTp0qlryyMjP55s1X8HplAOZefXh1+XFWDG3Li80cmfDHBK7EXWFZch/2/NWMl0a7Ur+1c7GUW9Zk3r1L5Pz5xO/YiWmDBtSaOwfLVpVjVtWjcv78ef3cf4WivFDQ91YIESClLDj0XS4qdUshKTYaKbOxqV6DwAjtG0iz2jZkZmfif9ufPi59CN15DzOjVOq0rF/G1j45UkoS9+7l9py5ZMXHU+29MTi89x4aUyUBrlAotJTomIIQopcQ4oIQ4rIQYmoB1z8SQpwTQgQJIQ4IIUo14HHOdFQbhxqcC0/AxtyY2rbmhESHkJyRjJeFC1fjGuPsnIaRcfkefsmIjOTmhAnc+nAiJjVr4vLLFm13kXIICoUiFyX2SyeEMAKWAb2BZsBgIcSD03dOA22llC2BX4AFlCK5F66dj0igWW0bhBD4RfghEDhdTCRNWuPasUlpmlWsSCmJ27qV0L79SD5ylBpTJuO8aSPmj9mfqlAoKjYl+fr7DHBZShkqpUwHNgI+uRNIKQ9KKVN0h35A/ukTJUhCVCQIgaW9A//cvi9v4RfhR9NqTYkMTsZYpFOvXfl0Cuk3b3Lj7beJmD4D8yZNcNm+jWpvv40wrtS9hgqFoghK8tehDpB7aeNNwKuI9G8DvxV0QQgxGhgNUL9+8fXtJ0RFYmVnz82EdFIzsmlWy4aUjBTORJ1haINXCY1xpn6dZExMjYqtzNJAZmVxd8MGIr9ejNBoqOn7OXYDBii9IoVC8VBK0ikUNH+zwKlOQog3gbbAcwVdl1L+APwA2tlHxWVgQnQkNrnkLZrWsiHgTgCZ2Zm4h5tzIbsarl42D8nl6SLt8mUips/g3pkzVOnSmVqzZmGSa4WlQqFQFEVJvjreBHKvda8LhD+YSAjxAjAd8JZSppWgPfnQBtfRjicYawSNHK3wi/DDVGOK6TmJhkycO7YsTZMeG5meTtR//sPV/q+Qfu0atRcuoN733yuHUAGoCNLZu3btolWrVnh4eNCsWTO+//57QLsy+ccff3wsmx6HsLCwAp/BoUOH6NevX6nZAWUjxW0IJdlS8AcaCSFcgFvAIGBI7gRCiFbA90AvKWWpLuHLzs4iMSaaJh1rcC4igYY1rDAzNsIvwo9WDu5c86tDXcd4zKo8/bNz7gWHEDFjBmkXLmDTpw+O06dhXK1aWZulKAZyS2ebmZkRHR1Neno6gwcPpnfv3nz55Zf6tIVJZ9erV6/YpbNzl/MwMjIyGD16NCdPnqRu3bqkpaXptYXGjBnzRHY9DWRmZmJcgcbpSqwmUspMIcR4YC9gBKySUp4VQswGTkkpdwILAStgi05o7rqU0rukbMpNUmws2VlZ2DjU4Lx/As82cCD6XjQX715kQpWXSciqSevWT7dDyE5NJWrpUmJXr8HYwYG6/1mGdS6tF0XxcvuLL0g7X7zS2WZN3ag5bVqh1yuCdHZiYiKZmZlU072omJmZ0aSJdvKGr68vVlZWTJ48GX9/f95++22qVKlCp06d+O233wgJCWHNmjVs376drKwsQkJCmDRpEunp6axbtw4zMzP27NlD1apVCQwMZMyYMaSkpNCgQQNWrVqFvb29Xr3U0tKSTp06PfQz8ff3Z/To0WzduhVHR0cmTJhAcHAwmZmZ+Pr64uPjw5o1a9i9ezepqakkJyczc+ZMfH19cXBwICQkhDZt2rB+/XqEEAQEBBQorf20UqIjj1LKPVLKxlLKBlLKebpzM3UOASnlC1JKRymlp24rFYcA2vEEAKztuZOQRrPaNpyMOAlAnctVgGxcnmtTWuY8MsknTxLq40PsylXYvfoqrrt+VQ6hAlIRpLOrVq2Kt7c3Tk5ODB48mA0bNuQRwMthxIgRfPfddxw/fhwjo7yTO0JCQvjpp584efIk06dPx9LSktOnT9OhQwd999PQoUP56quvCAoKwt3dXR+TYMSIx4gioQAAGlNJREFUESxZsqRQ0brcHDt2jDFjxrBjxw5cXV2ZN28ezz//PP7+/hw8eJApU6aQnJwMaFtxa9eu5Y8//gDg9OnTerXZ0NBQ/vrrLzIyMoqU1n4aqThtnkckZ+HanWxLIIamtWzYG+GHjakNibdqUss+Fku7woNslBVZSUlELlpE3MZNmNSrR/01q6nSvn1Zm1UpKOqNvqSoKNLZ//3vfwkODmb//v0sWrSI//3vf3mUW+Pi4khMTNSPXQwZMiSPMF63bt2wtrbG2toaW1tbvYNzd3cnKCiI+Ph44uLieO457VyVYcOG8frrr+c7/9Zbb/HbbwVOcuT8+fOMHj2affv2Ubt2bUAra71z504WLVoEaBVcr1+/DsCLL75I1apV9fc/88wzelFCT09PwsLCsLOzK1Ja+2mk0juFq6naoPNuNa3xDTzOs8KdmIz6dPLI/yZT1iQeOsRt31lkRkZSdfhwqr8/AU0h/+iKikN5l87Owd3dHXd3d9566y1cXFzy2PQwDbbcZWg0Gv2xRqMpMtSllIbHQKlVqxapqamcPn1a7xSklGzdulXf3ZXDiRMnipTFznkOD5PWfhqptBPXE6LuYGlrx/nIVGramJOUfZvbybdpdrMOAC7PtytjC++Tefcut6Z8zM0x76GxqoLzzz/hOPUT5RAqARVBOjspKUkfB6GgOgDY29tjbW2Nn58fgL5bzFBsbW2xt7fXd4OtW7eO5557Djs7O2xtbTl69ChAHvntB7Gzs2P37t1MmzZNb2/Pnj1ZunSp3mmdPn36kewqDmnt0qbythSio3TTURNpVtsGv3Dtl9H0Zk0srWOwqVH28QSklCTs2cOdufPISkrCYdw4qr07WukVVSIqgnS2lJIFCxbw7rvvYmFhQZUqVQpsuaxcuZJ33nmHKlWq0LVrV32XlKGsXbtWP9Ds6urK6tWrAW2kt5yB5oc5R0dHR3799Vd69+7NqlWr+Oyzz/jwww9p2bIlUkqcnZ3zdGs9DFNT0yeW1i5tKq109qoP36VqPWcmxXgw5jlXwk2/58r1i/Q8Pgmv9vdoO7xvMVj7+GTcucPtWbNJ+uMPzN3dqTV3LuZNGpepTZURJZ1deiQlJWFlZQVoB7QjIiL45ptvytiq8omSzn5EZHY2CdGR2Lp5khUlcatpxbZzJ3gppisArl0f+txKzjYpiduyhcgFC5GZmdT4+GOqDhuKMCpfUhsKxaOye/duvvzySzIzM3FycipyHERRclRKp5CSEE9WRgZxGu1biallBInpidS4VQ8Li7tUdS6bsJvp168T8dlMUk6cwPKZZ6g1ZzamTqWqJq5QlBkDBw7MF+heUfpUSqcQH3kHgPAsCyxNjbh+7wxmGZakJTekuWdSqdsjs7KI/XEdUd98gzA2puasWdi9/poSsFMoFKVOpXQKOQvXLqeY4FbTmhO3/fBKaIfECNeurUvVltSLF4mY8RmpQUFYde1KTd/PMalZs1RtUCgUihwq5atozhqFoDgNjWuac/rOaRpHNsHKNJ7qTUon7KZMTyfq22VcffU1Mm7coPa/FlF3+X+UQ1AoFGVK5WwpREViWsWKuxkarO1ukh0HJvGNcG2SYPBClyfhXlAQEdNnkHbpEjb9+mkF7AyY2qdQKBQlTSVtKdxBY61dnp4ozuES1xwpTWnQ+fFkhQ0l+9497sz/irBBg8lKSKDu8v9QZ9FC5RAURWJkZISnpyfNmzfHw8ODf//73wVqBxnCzJkz2b9/f6HXi0PKOjg4GE9PTzw9PalatSouLi54enrywgsvPFG+itKhcrYUoqNINbdFCLiSdBrPmPZYGCVRs1XJzUdP9jtBxGefkXHjBnYDB1Jj8iSMDJAQUCgsLCwIDAwEIDIykiFDhhAfH68XfHsUZs+eXeT14pCydnd319s7fPhw+vXrx2uvvZYvXUWTnK4oVLpPREpJfNQdYmvXxskBLkVfouvdYbg4J6DRFH/XUVZiIpELFhK3ZQsm9etTf+1aqng9U+zlKEqeI5svEn2jeGenOdSzovMAwxcl1qhRgx9++IF27drh6+tLdnY2U6dO5dChQ6SlpTFu3DjeffddABYsWMC6devQaDT07t1bL6SX8yM9depUdu7cibGxMT169GDRokV5pKwLk6Lu2rUrXl5eHDx4kLi4OFauXFng6ueC2L9/P/Pnz8fBwYGzZ88SHBzM2rVrWbZsGenp6XTs2JFvv/0WjUbDb7/9xuzZs0lLS6NRo0asWrUqn96QovipdE7hXmICmWlp3Mwwp4bjTapEN4ZsC1w71Cj2shL/OMhtX18yo6OpOnIk1SeMR2Px9CmvKsoXrq6uZGdnExkZyY4dO7C1tcXf35+0tDSeffZZevTowT///MP27ds5ceIElpaWxMbG5skjNjaWbdu28c8//yCEIC4uLl85Q4cOZenSpTz33HPMnDmTWbNmsXjxYkD7ln/y5En27NnDrFmziuySehA/Pz/OnTtH/fr1CQkJYdu2bRw7dgxjY2NGjx7Nxo0beeGFF5g/fz4HDhzA0tKSefPm8c033zCtDJRqKxuVzinkzDy6kW5OdYuLNIr1wFRzj7rtCwwP/VhkxsZyZ+48EvbswaxxY+ou+xYLd/diy19RNjzKG31JkyNPs2/fPoKCgvRhHePj47l06RL79+9nxIgRerns3BLPADY2NpibmzNq1Cj69u2bLxRlYVLUObzyyisAtGnTRh9FzVA6dOhA/fraWX779+/H39+ftm21KgL37t2jXr16WFpacu7cOb2Udnp6ukEBchRPTuVzCro1CgnG1pAWTMeYcTjVjsPI5MllJKSUJOzaxZ15X5CVnIzD+xNwGDUKoQTsFMVIaGgoRkZG1KhRAyklS5cuzSf09vvvvxc5k87Y2JiTJ09y4MABNm7cyLfffqsPFmMIOTLRRUllF0buLiApJSNHjmTOnDl50mzbto1evXoVGClOUbJUutlHCbrVzEkWmZhEV8E4y5oGbfNLDj8qGRER3BzzHuFTPsbEqT6u/7eV6mPHKoegKFaioqIYM2YM48ePRwhBz549Wb58ORkZGQBcvHiR5ORkevTowapVq0hJSQHI132UlJREfHw8ffr0YfHixfqB4RwKk6Iubl544QU2b95MdHQ0ADExMVy/fp2OHTvy559/EhoaCkBycnIeCXFFyVEJWwpRZBubYV7tFi6xLdGIdOp36fbY+cnsbOI2byZy4SJkdjaOn07F/s03lYCdoti4d+8enp6eZGRkYGxszFtvvcVHH30EwKhRowgLC6N169ZIKalevTrbt2+nV69eBAYG0rZtW0xNTenTpw9ffPGFPs/ExER8fHxITU1FSsnXX3+dr9zCpKiLE3d3dz7//HNeeOEFsrOzMTEx4bvvvqNdu3asXLmSgQMHkp6eDsAXX3yRJ9yoomSodNLZ2xbMJuj8VfZ3knifeYnmdin0mf3WY+WVHhamFbDz98eyQ3tqzZ6N6QNhCBXlGyWdrSiPKOnsRyAhKpJoYYlVagSW6fY0aPXoU9xkZiaxa9cStWQpwtSUWnPnYPvqq6WyGlqhUChKkkrnFOKiIkkwc6R2TBMgE6fnn32k+1MvXCBi+gxSQ0Kw6t6dmjNnYuJY/NNZFQqFoiyoVE4hNTmJzHspJFdNoVXsszjaR2Bua9iq4uz0dGK++47oH1ZgZGtLncVfY92zp2odKBSKCkWlcgo5axQsLRKxi6mB2zOGBSBPOX2aiBmfkX7lCrY+3tSYOlXpFSkUigpJpXQKVWR1JNm4PN+hyPTZKSlELl7M3XXrMa5Zk3o/fI9Vly6lYapCoVCUCZXKKcRHadco1EzxoIr1LarULFy1MfnYMSI+m0nGrVvYDxlM9Y8+wkgXVFyhUCgqKpVq8dqdWxFkCUG1ew1o1sSkwDRZCQmET5/O9ZFvI4yNcVr3IzVnzlQOQVFm5Ehnt2jRgpdeeqlAnaLHISwsjBYtil8u3tfXlzp16ujls6dOnVrsZeQQGBjInj17Siz/ykilcgoR4RFkmpoghMCte8d81xP37ye0bz/it++g2jvv4LJjO5bt2pWBpQrFfXKks0NCQqhatSrLli0ra5MeysSJEwkMDCQwMJD58+cbfF9WVtYjlaOcQvFTqbqP4iIj0Ag7pGU4ti7P689nRkdze+48En//HTM3N+ouX45Fi+ZlaKniaeTgmh+IvBZarHnWcHKl2/DRBqfv0KEDQUFBgFaqwsfHh7t375KRkcHcuXPx8fEhLCyM3r1706lTJ44dO0adOnXYsWMHFhYWBAQEMHLkSCwtLfMIzKWmpvLee+9x6tQpjI2N+fe//023bt1Ys2YN27dvJysri5CQECZNmkR6ejrr1q3DzMyMPXv25BPbK4wDBw4wefJkMjMzadeuHcuXL8fMzAxnZ2dGjhzJvn37GD9+PO3atWPcuHFERUVhaWnJihUrcHNzY8uWLcyaNQsjIyNsbW3Zv38/M2fO5N69exw9epRPP/2UgQMHPtoHoMhHpWopZMVHYZbtSD2nZEArxhW3fTtX+vYj6cABqn/4IS5bNiuHoHgqycrK4sCBA3h7ewNgbm7Otm3b+Pvvvzl48CCTJk3Sq6deunSJcePGcfbsWezs7Ni6dSsAI0aMYMmSJRw/fjxP3jmtj+DgYH7++WeGDRtGamoqACEhIfz000+cPHmS6dOnY2lpyenTp+nQoUOhUdq+/vprfffR3r17SU1NZfjw4WzatIng4GAyMzNZvny5Pr25uTlHjx5l0KBBjB49mqVLlxIQEMCiRYsYO3YsoA0QtHfvXs6cOcPOnTsxNTVl9uzZDBw4kMDAQOUQiolK01JIT72HUUYGGgtb2j/fnozwcCI+9yX5yBEsPD2pNW8uZg0alLWZiqeYR3mjL05ytI/CwsJo06YNL774IqB9qZk2bRqHDx9Go9Fw69Yt7tzRTqbICYEJ9+WtH5TDfuutt/jtt98AOHr0KBMmTADAzc0NJycnLl68CEC3bt2wtrbG2toaW1tbXnrpJUCrW5TTanmQiRMnMnnyZP3xmTNncHFxoXFjrfz4sGHDWLZsGR9++CGA/gc9KSmJY8eO5ZHpTktLA+DZZ59l+PDhDBgwQC/drSh+SrSlIIToJYS4IIS4LITIN9okhDATQmzSXT8hhHAuKVuiwm8DkGkqMT4TQmi/l0gJCMBx+nScNqxXDkHx1JIzpnDt2jXS09P1b/UbNmwgKiqKgIAAAgMDcXR01L/d50hbw315aylloYsti9JAy52XRqPRH2s0GoNlsx+msZYjp52dnY2dnZ1+PCIwMJDz588D2vjRc+fO5caNG3h6ehITE2NQ2YpHo8ScghDCCFgG9AaaAYOFEM0eSPY2cFdK2RD4GviqpOw5ceovABzjI4mcOxcLT09cd+6k6ltK0VRRPrC1tWXJkiUsWrSIjIwM4uPjqVGjBiYmJhw8eJBr164Veb+dnR22trYcPXoU0DqVHLp06aI/vnjxItevX6dJkybFZrubmxthYWFcvnwZKFyK28bGBhcXF7Zs2QJoncmZM2cAuHLlCl5eXsyePRsHBwdu3LiBtbU1iYmGLUJVGEZJthSeAS5LKUOllOnARsDngTQ+wFrd/i9Ad1FCuhGR+w8DUO/2ZWp98QX1Vv4X07p1SqIohaLEaNWqFR4eHmzcuJE33niDU6dO0bZtWzZs2ICbm9tD71+9ejXjxo2jQ4cOWOQKDTt27FiysrJwd3dn4MCBrFmzJk8L4UkxNzdn9erVvP7667i7u6PRaBgzZkyBaTds2MDKlSvx8PCgefPm7NixA4ApU6bg7u5OixYt6NKlCx4eHnTr1o1z587h6enJpk2bis3eykyJSWcLIV4DekkpR+mO3wK8pJTjc6UJ0aW5qTu+oksT/UBeo4HRAPXr12/zsDeiglgxZSIpN+MYvXAuFsoZKAxESWcryiNPq3R2QW/8D3ogQ9IgpfwB+AG08RQex5h3FuYPIqJQKBSKvJRk99FNIHfEmbpAeGFphBDGgC0Qi0KhUCjKhJJ0Cv5AIyGEixDCFBgE7HwgzU5gmG7/NeAPWd5CwSkqPOorqShPPOn3tcScgpQyExgP7AXOA5ullGeFELOFEN66ZCuBakKIy8BHQMmJpCgUj4G5uTkxMTHKMSjKBVJKYmJiMDc3f+w8Kl2MZoXiUcjIyODmzZv6+f8KxdOOubk5devWxcQkr+jn0zDQrFCUe0xMTHBxcSlrMxSKUqNSaR8pFAqFomiUU1AoFAqFHuUUFAqFQqGn3A00CyGigEdf0qzFAYh+aKqKhapz5UDVuXLwJHV2klJWf1iicucUngQhxClDRt8rEqrOlQNV58pBadRZdR8pFAqFQo9yCgqFQqHQU9mcwg9lbUAZoOpcOVB1rhyUeJ0r1ZiCQqFQKIqmsrUUFAqFQlEEyikoFAqFQk+FdApCiF5CiAtCiMtCiHzKq0IIMyHEJt31E0II59K3sngxoM4fCSHOCSGChBAHhBBOZWFncfKwOudK95oQQgohyv30RUPqLIQYoPuszwohfiptG4sbA77b9YUQB4UQp3Xf7z5lYWdxIYRYJYSI1EWmLOi6EEIs0T2PICFE62I1QEpZoTbACLgCuAKmwBmg2QNpxgLf6fYHAZvK2u5SqHM3wFK3/15lqLMunTVwGPAD2pa13aXwOTcCTgP2uuMaZW13KdT5B+A93X4zIKys7X7COncBWgMhhVzvA/yGNnJle+BEcZZfEVsKzwCXpZShUsp0YCPg80AaH2Ctbv8XoLsQoqDQoOWFh9ZZSnlQSpmiO/RDGwmvPGPI5wwwB1gAVATta0Pq/A6wTEp5F0BKGVnKNhY3htRZAja6fVvyR3gsV0gpD1N0BEof4EepxQ+wE0LUKq7yK6JTqAPcyHV8U3euwDRSGwwoHqhWKtaVDIbUOTdvo33TKM88tM5CiFZAPSnlrtI0rAQx5HNuDDQWQvwlhPATQvQqNetKBkPq7Au8KYS4CewBJpSOaWXGo/6/PxIVMZ5CQW/8D867NSRNecLg+ggh3gTaAs+VqEUlT5F1FkJogK+B4aVlUClgyOdsjLYLqSva1uARIUQLKWVcCdtWUhhS58HAGinlv4QQHYB1ujpnl7x5ZUKJ/n5VxJbCTaBeruO65G9O6tMIIYzRNjmLaq497RhSZ4QQLwDTAW8pZVop2VZSPKzO1kAL4JAQIgxt3+vOcj7YbOh3e4eUMkNKeRW4gNZJlFcMqfPbwGYAKeVxwBytcFxFxaD/98elIjoFf6CREMJFCGGKdiB55wNpdgLDdPuvAX9I3QhOOeWhddZ1pXyP1iGU935meEidpZTxUkoHKaWzlNIZ7TiKt5SyPMdyNeS7vR3tpAKEEA5ou5NCS9XK4sWQOl8HugMIIZqidQpRpWpl6bITGKqbhdQeiJdSRhRX5hWu+0hKmSmEGA/sRTtzYZWU8qwQYjZwSkq5E1iJtol5GW0LYVDZWfzkGFjnhYAVsEU3pn5dSuldZkY/IQbWuUJhYJ33Aj2EEOeALGCKlDKm7Kx+Mgys8yRghRBiItpulOHl+SVPCPEz2u4/B904yeeACYCU8ju04yZ9gMtACjCiWMsvx89OoVAoFMVMRew+UigUCsVjopyCQqFQKPQop6BQKBQKPcopKBQKhUKPcgoKhUKh0KOcguKpRQiRJYQIzLU5F5HWuTBVydJGCNFWCLFEt99VCNEx17UxQoihpWiLZ3lXDVWULhVunYKiQnFPSulZ1kY8KroFcjmL5LoCScAx3bXvirs8IYSxTsOrIDzRyprsKe5yFRUT1VJQlCt0LYIjQoi/dVvHAtI0F0Kc1LUugoQQjXTn38x1/nshhFEB94YJIb7SpTsphGioO+8ktHEocuJR1Nedf10IESKEOCOEOKw711UIsUvXshkDTNSV2VkI4SuEmCyEaCqEOPlAvYJ0+22EEH8KIQKEEHsLUsAUQqwRQvxbCHEQ+EoI8YwQ4pjQxhQ4JoRoolsBPBsYqCt/oBCiitDq9fvr0hakLKuozJS1drja1FbYhnZFbqBu26Y7ZwmY6/YboV3VCuCMTn8eWAq8ods3BSyApsCvgInu/H+AoQWUGQZM1+0PBXbp9n8Fhun2RwLbdfvBQB3dvp3ub9dc9/kCk3Plrz/W1ctVt/8JMAPtytVjQHXd+YFoV/E+aOcaYBdgpDu2AYx1+y8AW3X7w4Fvc933BfBmjr3ARaBKWX/Want6NtV9pHiaKaj7yAT4VgjhidZpNC7gvuPAdCFEXeD/pJSXhBDdgTaAv07mwwIoTAPq51x/v9btdwBe0e2vQxujAeAvYI0QYjPwf49SObQibgOA+Wh//AcCTdAK+f1PZ6cRUJiuzRYpZZZu3xZYq2sVSXSyCAXQA/AWQkzWHZsD9YHzj2i7ooKinIKivDERuAN4oO3+zBc8R0r5kxDiBNAX2CuEGIVWbnitlPJTA8qQheznSyOlHCOE8NKVFahzVoayCa0W1f9ps5KXhBDuwFkpZQcD7k/OtT8HOCil7K/rtjpUyD0CeFVKeeER7FRUItSYgqK8YQtESK1W/lto36TzIIRwBUKllEvQKkq2BA4ArwkhaujSVBWFx6kemOvvcd3+Me4LJ74BHNXl00BKeUJKOROIJq+kMUAiWhnvfEgpr6Bt7XyG1kGAVuq6utDGBUAIYSKEaF6InbmxBW7p9ocXUf5eYILQNUOEVj1XodCjnIKivPEfYJgQwg9t11FyAWkGAiFCiEDADW3ownNo++z36QZ0/wcUFsLQTNfS+ABtywTgfWCE7t63dNcAFgohgnXTYQ+jjSGcm1+B/jkDzQWUtQl4k/vxANLRyrl/JYQ4g3bcId9gegEsAL4UQvxFXkd5EGiWM9CMtkVhAgTpbJ5jQN6KSoRSSVUociG0AXnaSimjy9oWhaIsUC0FhUKhUOhRLQWFQqFQ6FEtBYVCoVDoUU5BoVAoFHqUU1AoFAqFHuUUFAqFQqFHOQWFQqFQ6Pl/5PYmZZFI2EIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlv-H9NVuyDv",
        "colab_type": "text"
      },
      "source": [
        "## Tune Hyperparameters\n",
        "\n",
        "### SVM\n",
        "\n",
        "We use GridSearchCV to implement the tuning. Since with different kernels, the parameters are different, we seprate three kernels to two group, those are kernels of linear and Gaussian, and kernel of polynomial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryu09VZSuyDw",
        "colab_type": "code",
        "outputId": "a24222a6-dd3c-4076-b265-1432b1419b50",
        "colab": {}
      },
      "source": [
        "# Kernels of linear and Gaussian\n",
        "import time\n",
        "\n",
        "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
        "gammas = [0.001, 0.01, 0.1, 1, 10]\n",
        "param_grid = {'kernel':['linear', 'rbf'], 'C': Cs, 'gamma':gammas}\n",
        "\n",
        "# for kernels of linear\n",
        "svc_rbf_lin = SVC()\n",
        "start = time.time()\n",
        "gridsearch_rbf_lin = GridSearchCV(svc_rbf_lin, param_grid, cv=10)\n",
        "gridsearch_rbf_lin.fit(X_train, y_train)\n",
        "print(gridsearch_rbf_lin.best_estimator_, '\\n',gridsearch_rbf_lin.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #275s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False) \n",
            " 0.8692493946731235\n",
            "It cost 306.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Q1WPGHDPuyDx",
        "colab_type": "code",
        "outputId": "09afc138-20b9-4875-d298-ef29ecebfba7",
        "colab": {}
      },
      "source": [
        "param_grid = {'degree': [int(x) for x in np.linspace(start = 2, stop = 10, num = 9)]} # degree=1 is linear kernel\n",
        "svc_poly = SVC(kernel='poly')\n",
        "start = time.time()\n",
        "gridsearch_poly = GridSearchCV(svc_poly, param_grid)\n",
        "gridsearch_poly.fit(X_train, y_train)\n",
        "print(gridsearch_poly.best_estimator_, '\\n',gridsearch_poly.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #485s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
            "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
            "  shrinking=True, tol=0.001, verbose=False) \n",
            " 0.8553268765133172\n",
            "It cost 485.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hjr7TveWuyDz",
        "colab_type": "code",
        "outputId": "2e3d6e79-cd62-477e-8afd-4c7364ff9860",
        "colab": {}
      },
      "source": [
        "# Evaluate poly kernel in validation set\n",
        "svclassifier_poly = SVC(kernel='poly', degree=2)\n",
        "svclassifier_poly.fit(X_train, y_train)\n",
        "# Doin predictions\n",
        "y_poly_pred = svclassifier_poly.predict(X_valid)\n",
        "# result\n",
        "s_poly = round(svclassifier_poly.score(X_valid, y_valid), 3)\n",
        "c_poly = confusion_matrix(y_valid, y_poly_pred)\n",
        "cr_poly = classification_report(y_valid, y_poly_pred)\n",
        "print(\"When degree=2, the score is {0}, the confusion matrix is \\n{1}, the report is\\n {2}\".format(s_poly, c_poly, cr_poly))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "When degree=2, the score is 0.861, the confusion matrix is \n",
            "[[146  16]\n",
            " [ 30 140]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       162\n",
            "           1       0.90      0.82      0.86       170\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       332\n",
            "   macro avg       0.86      0.86      0.86       332\n",
            "weighted avg       0.86      0.86      0.86       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_boFjQktuyD1",
        "colab_type": "code",
        "outputId": "f083e1f5-f258-4209-cd12-6ba5fa59fc69",
        "colab": {}
      },
      "source": [
        "# Evaluate poly kernel in test set\n",
        "svclassifier_poly = SVC(kernel='poly', degree=2)\n",
        "svclassifier_poly.fit(X_train, y_train)\n",
        "# Doin predictions\n",
        "y_poly_pred = svclassifier_poly.predict(X_test)\n",
        "# result\n",
        "s_poly = round(svclassifier_poly.score(X_test, y_test), 3)\n",
        "c_poly = confusion_matrix(y_test, y_poly_pred)\n",
        "cr_poly = classification_report(y_test, y_poly_pred)\n",
        "print(\"When degree=2, the score is {0}, the confusion matrix is \\n{1}, the report is\\n {2}\".format(s_poly, c_poly, cr_poly))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "When degree=2, the score is 0.875, the confusion matrix is \n",
            "[[165  16]\n",
            " [ 28 143]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       181\n",
            "           1       0.90      0.84      0.87       171\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       352\n",
            "   macro avg       0.88      0.87      0.87       352\n",
            "weighted avg       0.88      0.88      0.87       352\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Tuq9R0uyD3",
        "colab_type": "code",
        "outputId": "ac70df6d-035f-43b1-92a8-82f5afd5778f",
        "colab": {}
      },
      "source": [
        "gridsearch_rbf_lin.cv_results_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.0736382 , 0.0658354 , 0.06766661, 0.065792  , 0.06583254,\n",
              "        0.06640848, 0.0658257 , 0.06582435, 0.06547999, 0.06549033,\n",
              "        0.06881595, 0.06902107, 0.06882556, 0.06874998, 0.06915895,\n",
              "        0.06849329, 0.06869809, 0.06915426, 0.06881714, 0.06813033]),\n",
              " 'std_fit_time': array([4.93238519e-03, 2.14391906e-03, 8.36295761e-04, 2.47405965e-03,\n",
              "        2.14633454e-03, 2.51145938e-03, 1.41040247e-03, 2.15402018e-03,\n",
              "        1.70683314e-03, 1.69451579e-03, 8.14004070e-04, 5.88771043e-04,\n",
              "        1.41309807e-05, 7.11008851e-04, 4.63806619e-04, 4.76148519e-04,\n",
              "        6.49578243e-04, 9.41564263e-04, 8.17216700e-04, 5.06946053e-04]),\n",
              " 'mean_score_time': array([0.021463  , 0.01994665, 0.01994387, 0.02597117, 0.02027957,\n",
              "        0.018653  , 0.02061041, 0.01994689, 0.02027806, 0.01994705,\n",
              "        0.01698295, 0.01761977, 0.01795244, 0.0179526 , 0.01762287,\n",
              "        0.01795268, 0.01464836, 0.01795014, 0.01795109, 0.0182964 ]),\n",
              " 'std_score_time': array([1.49242345e-03, 2.97360213e-07, 2.32245750e-06, 8.50390105e-03,\n",
              "        4.69403753e-04, 1.84726827e-03, 4.68898102e-04, 1.12391596e-07,\n",
              "        4.68954025e-04, 1.94667955e-07, 2.11588464e-03, 4.70134086e-04,\n",
              "        7.01885292e-07, 1.80877156e-06, 4.72186349e-04, 1.66324373e-06,\n",
              "        4.67099493e-03, 1.47400196e-06, 2.97996732e-06, 4.61049273e-04]),\n",
              " 'param_C': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
              "                    0.05, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
              "                    0.11, 0.11],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_gamma': masked_array(data=[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
              "                    0.009000000000000001, 0.01, 0.001, 0.002, 0.003, 0.004,\n",
              "                    0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.01],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'linear',\n",
              "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
              "                    'linear', 'linear', 'linear', 'linear', 'linear',\n",
              "                    'linear', 'linear', 'linear', 'linear', 'linear'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'C': 0.05, 'gamma': 0.001, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.002, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.003, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.004, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.005, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.006, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.007, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.008, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.009000000000000001, 'kernel': 'linear'},\n",
              "  {'C': 0.05, 'gamma': 0.01, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.001, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.002, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.003, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.004, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.005, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.006, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.007, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.008, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.009000000000000001, 'kernel': 'linear'},\n",
              "  {'C': 0.11, 'gamma': 0.01, 'kernel': 'linear'}],\n",
              " 'split0_test_score': array([0.87137681, 0.87137681, 0.87137681, 0.87137681, 0.87137681,\n",
              "        0.87137681, 0.87137681, 0.87137681, 0.87137681, 0.87137681,\n",
              "        0.86231884, 0.86231884, 0.86231884, 0.86231884, 0.86231884,\n",
              "        0.86231884, 0.86231884, 0.86231884, 0.86231884, 0.86231884]),\n",
              " 'split1_test_score': array([0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182,\n",
              "        0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182,\n",
              "        0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182,\n",
              "        0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182]),\n",
              " 'split2_test_score': array([0.86181818, 0.86181818, 0.86181818, 0.86181818, 0.86181818,\n",
              "        0.86181818, 0.86181818, 0.86181818, 0.86181818, 0.86181818,\n",
              "        0.86727273, 0.86727273, 0.86727273, 0.86727273, 0.86727273,\n",
              "        0.86727273, 0.86727273, 0.86727273, 0.86727273, 0.86727273]),\n",
              " 'mean_test_score': array([0.87046005, 0.87046005, 0.87046005, 0.87046005, 0.87046005,\n",
              "        0.87046005, 0.87046005, 0.87046005, 0.87046005, 0.87046005,\n",
              "        0.86924939, 0.86924939, 0.86924939, 0.86924939, 0.86924939,\n",
              "        0.86924939, 0.86924939, 0.86924939, 0.86924939, 0.86924939]),\n",
              " 'std_test_score': array([0.00670789, 0.00670789, 0.00670789, 0.00670789, 0.00670789,\n",
              "        0.00670789, 0.00670789, 0.00670789, 0.00670789, 0.00670789,\n",
              "        0.00662679, 0.00662679, 0.00662679, 0.00662679, 0.00662679,\n",
              "        0.00662679, 0.00662679, 0.00662679, 0.00662679, 0.00662679]),\n",
              " 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 11, 11, 11, 11, 11, 11, 11,\n",
              "        11, 11, 11]),\n",
              " 'split0_train_score': array([0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182,\n",
              "        0.87818182, 0.87818182, 0.87818182, 0.87818182, 0.87818182,\n",
              "        0.89454545, 0.89454545, 0.89454545, 0.89454545, 0.89454545,\n",
              "        0.89454545, 0.89454545, 0.89454545, 0.89454545, 0.89454545]),\n",
              " 'split1_train_score': array([0.88294011, 0.88294011, 0.88294011, 0.88294011, 0.88294011,\n",
              "        0.88294011, 0.88294011, 0.88294011, 0.88294011, 0.88294011,\n",
              "        0.88747731, 0.88747731, 0.88747731, 0.88747731, 0.88747731,\n",
              "        0.88747731, 0.88747731, 0.88747731, 0.88747731, 0.88747731]),\n",
              " 'split2_train_score': array([0.88203267, 0.88203267, 0.88203267, 0.88203267, 0.88203267,\n",
              "        0.88203267, 0.88203267, 0.88203267, 0.88203267, 0.88203267,\n",
              "        0.89110708, 0.89110708, 0.89110708, 0.89110708, 0.89110708,\n",
              "        0.89110708, 0.89110708, 0.89110708, 0.89110708, 0.89110708]),\n",
              " 'mean_train_score': array([0.88105153, 0.88105153, 0.88105153, 0.88105153, 0.88105153,\n",
              "        0.88105153, 0.88105153, 0.88105153, 0.88105153, 0.88105153,\n",
              "        0.89104328, 0.89104328, 0.89104328, 0.89104328, 0.89104328,\n",
              "        0.89104328, 0.89104328, 0.89104328, 0.89104328, 0.89104328]),\n",
              " 'std_train_score': array([0.00206273, 0.00206273, 0.00206273, 0.00206273, 0.00206273,\n",
              "        0.00206273, 0.00206273, 0.00206273, 0.00206273, 0.00206273,\n",
              "        0.00288591, 0.00288591, 0.00288591, 0.00288591, 0.00288591,\n",
              "        0.00288591, 0.00288591, 0.00288591, 0.00288591, 0.00288591])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8aNwUIluyD5",
        "colab_type": "text"
      },
      "source": [
        "c=10, gamma =0.001\n",
        "c=10, gamma = 0.01\n",
        "c=1, gamma=0.01\n",
        "c is larger, tends to overfitting, try to c = [1, 10], gamma [0.001, 0.01]\n",
        "\n",
        "for polynomial kernel, use degree as parameter, when degree=2, score in training set is 0.8553, in validation set is 0.861, worse than linear kernel. drop this kernel.\n",
        "\n",
        "Second round of linear kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rspycApuyD6",
        "colab_type": "code",
        "outputId": "7814c958-5e6e-4b21-f47b-84cdf4413764",
        "colab": {}
      },
      "source": [
        "import time\n",
        "Cs = [x for x in np.linspace(start = 1, stop = 10, num = 10)]\n",
        "gammas = [x for x in np.linspace(start = 0.001, stop = 0.01, num = 10)]\n",
        "param_grid = {'kernel':['linear'], 'C': Cs, 'gamma':gammas}\n",
        "\n",
        "# for kernels of linear\n",
        "svc_rbf_lin = SVC()\n",
        "start = time.time()\n",
        "gridsearch_rbf_lin = GridSearchCV(svc_rbf_lin, param_grid)\n",
        "gridsearch_rbf_lin.fit(X_train, y_train)\n",
        "print(gridsearch_rbf_lin.best_estimator_, '\\n',gridsearch_rbf_lin.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #275s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=9.0, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False) \n",
            " 0.862590799031477\n",
            "It cost 227.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89YrCGlzuyD8",
        "colab_type": "text"
      },
      "source": [
        "second round results: C = 9, any gamma, acc=0.8626; c=8,10, any gamma acc=0.8620\n",
        "C = 1,7, any gamma, acc=0.8608\n",
        "\n",
        "\n",
        "Evaluate whether overfitting in C=9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gsSlAfAcuyD8",
        "colab_type": "code",
        "outputId": "bec9d793-15de-4c3d-efd5-1118a498f227",
        "colab": {}
      },
      "source": [
        "# Evaluate in validation set\n",
        "Cs = [1, 9]\n",
        "for c in Cs:\n",
        "    svclassifier_lin = SVC(kernel='linear', C=c, gamma='scale')\n",
        "    svclassifier_lin.fit(X_train, y_train)\n",
        "    # Doin predictions\n",
        "    y_lin_pred = svclassifier_lin.predict(X_valid)\n",
        "    # result\n",
        "    print(\"\\nWhen C=\", c,'\\n')\n",
        "    s_lin = round(svclassifier_lin.score(X_valid, y_valid), 3)\n",
        "    c_lin = confusion_matrix(y_valid, y_lin_pred)\n",
        "    cr_lin = classification_report(y_valid, y_lin_pred)\n",
        "    print(\"When c={0}, the score is {1}, the confusion matrix is \\n{2}, the report is\\n {3}\".format(c, s_lin, c_lin, cr_lin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "When C= 1 \n",
            "\n",
            "When c=1, the score is 0.873, the confusion matrix is \n",
            "[[146  16]\n",
            " [ 26 144]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87       162\n",
            "           1       0.90      0.85      0.87       170\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       332\n",
            "   macro avg       0.87      0.87      0.87       332\n",
            "weighted avg       0.88      0.87      0.87       332\n",
            "\n",
            "\n",
            "When C= 9 \n",
            "\n",
            "When c=9, the score is 0.867, the confusion matrix is \n",
            "[[145  17]\n",
            " [ 27 143]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       162\n",
            "           1       0.89      0.84      0.87       170\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       332\n",
            "   macro avg       0.87      0.87      0.87       332\n",
            "weighted avg       0.87      0.87      0.87       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zb63YYzuyD-",
        "colab_type": "text"
      },
      "source": [
        "When c=1, score is 0.873, when c =9, the score is 0.867. choose c=1\n",
        "\n",
        "Third round"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJxQKtHuyD_",
        "colab_type": "code",
        "outputId": "884997d2-fe63-475c-ee79-1fcc0bbea3ea",
        "colab": {}
      },
      "source": [
        "import time\n",
        "Cs = [x for x in np.linspace(start = 0.05, stop = 2, num = 25)]\n",
        "gammas = [x for x in np.linspace(start = 0.001, stop = 0.01, num = 10)]\n",
        "param_grid = {'kernel':['linear'], 'C': Cs, 'gamma':gammas}\n",
        "\n",
        "# for kernels of linear\n",
        "svc_rbf_lin = SVC()\n",
        "start = time.time()\n",
        "gridsearch_rbf_lin = GridSearchCV(svc_rbf_lin, param_grid)\n",
        "gridsearch_rbf_lin.fit(X_train, y_train)\n",
        "print(gridsearch_rbf_lin.best_estimator_, '\\n',gridsearch_rbf_lin.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) # 130s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False) \n",
            " 0.8686440677966102\n",
            "It cost 129.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2J8kbS8vuyEA",
        "colab_type": "code",
        "outputId": "1041fc48-3e68-4a0b-9ef1-b3a8b75edf25",
        "colab": {}
      },
      "source": [
        "# Evaluate in validation set\n",
        "Cs = [0.1, 1.7, 1.8]\n",
        "for c in Cs:\n",
        "    svclassifier_lin = SVC(kernel='linear', C=c, gamma='scale')\n",
        "    svclassifier_lin.fit(X_train, y_train)\n",
        "    # Doin predictions\n",
        "    y_lin_pred = svclassifier_lin.predict(X_valid)\n",
        "    # result\n",
        "    print(\"\\nWhen C=\", c,'\\n')\n",
        "    s_lin = round(svclassifier_lin.score(X_valid, y_valid), 3)\n",
        "    c_lin = confusion_matrix(y_valid, y_lin_pred)\n",
        "    cr_lin = classification_report(y_valid, y_lin_pred)\n",
        "    print(\"When c={0}, the score is {1}, the confusion matrix is \\n{2}, the report is\\n {3}\".format(c, s_lin, c_lin, cr_lin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "When C= 0.1 \n",
            "\n",
            "When c=0.1, the score is 0.88, the confusion matrix is \n",
            "[[148  14]\n",
            " [ 26 144]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       162\n",
            "           1       0.91      0.85      0.88       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n",
            "\n",
            "When C= 1.7 \n",
            "\n",
            "When c=1.7, the score is 0.867, the confusion matrix is \n",
            "[[144  18]\n",
            " [ 26 144]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87       162\n",
            "           1       0.89      0.85      0.87       170\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       332\n",
            "   macro avg       0.87      0.87      0.87       332\n",
            "weighted avg       0.87      0.87      0.87       332\n",
            "\n",
            "\n",
            "When C= 1.8 \n",
            "\n",
            "When c=1.8, the score is 0.864, the confusion matrix is \n",
            "[[144  18]\n",
            " [ 27 143]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86       162\n",
            "           1       0.89      0.84      0.86       170\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       332\n",
            "   macro avg       0.87      0.87      0.86       332\n",
            "weighted avg       0.87      0.86      0.86       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s0olYOLuyEC",
        "colab_type": "text"
      },
      "source": [
        "third round evaluation in validation :When c=0.1, score is 0.88, when c =1.7, the score is 0.867, when c =1., the score is 0.864. choose c=0.1.\n",
        "\n",
        "Since best c from 1 to 0.1, we have to make the fourth hone in.\n",
        "\n",
        "fourth round c=[0.05, 0.2], gamma=’scaled’\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZrtBm76uyEC",
        "colab_type": "code",
        "outputId": "10e8aacf-e608-45f2-a4f9-f11cfc6a65eb",
        "colab": {}
      },
      "source": [
        "import time\n",
        "Cs = [x for x in np.linspace(start = 0.05, stop = 0.2, num = 16)]\n",
        "gammas = [x for x in np.linspace(start = 0.001, stop = 0.01, num = 10)]\n",
        "param_grid = {'kernel':['linear'], 'C': Cs, 'gamma':gammas}\n",
        "\n",
        "# for kernels of linear\n",
        "svc_rbf_lin = SVC()\n",
        "start = time.time()\n",
        "gridsearch_rbf_lin = GridSearchCV(svc_rbf_lin, param_grid)\n",
        "gridsearch_rbf_lin.fit(X_train, y_train)\n",
        "print(gridsearch_rbf_lin.best_estimator_, '\\n',gridsearch_rbf_lin.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=0.05, cache_size=200, class_weight=None, coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
            "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False) \n",
            " 0.8704600484261501\n",
            "It cost 59.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FVeIQdaFuyEE",
        "colab_type": "code",
        "outputId": "3c3846d9-123f-4216-9b53-cac1e33cdadf",
        "colab": {}
      },
      "source": [
        "# Evaluate in validation set\n",
        "Cs = [0.05, 0.08, 0.11, 0.13]\n",
        "for c in Cs:\n",
        "    svclassifier_lin = SVC(kernel='linear', C=c, gamma='scale')\n",
        "    svclassifier_lin.fit(X_train, y_train)\n",
        "    # Doin predictions\n",
        "    y_lin_pred = svclassifier_lin.predict(X_valid)\n",
        "    # result\n",
        "    print(\"\\nWhen C=\", c,'\\n')\n",
        "    s_lin = round(svclassifier_lin.score(X_valid, y_valid), 3)\n",
        "    c_lin = confusion_matrix(y_valid, y_lin_pred)\n",
        "    cr_lin = classification_report(y_valid, y_lin_pred)\n",
        "    print(\"When c={0}, the score is {1}, the confusion matrix is \\n{2}, the report is\\n {3}\".format(c, s_lin, c_lin, cr_lin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "When C= 0.05 \n",
            "\n",
            "When c=0.05, the score is 0.88, the confusion matrix is \n",
            "[[149  13]\n",
            " [ 27 143]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88       162\n",
            "           1       0.92      0.84      0.88       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n",
            "\n",
            "When C= 0.08 \n",
            "\n",
            "When c=0.08, the score is 0.877, the confusion matrix is \n",
            "[[148  14]\n",
            " [ 27 143]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       162\n",
            "           1       0.91      0.84      0.87       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n",
            "\n",
            "When C= 0.11 \n",
            "\n",
            "When c=0.11, the score is 0.88, the confusion matrix is \n",
            "[[148  14]\n",
            " [ 26 144]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       162\n",
            "           1       0.91      0.85      0.88       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n",
            "\n",
            "When C= 0.13 \n",
            "\n",
            "When c=0.13, the score is 0.877, the confusion matrix is \n",
            "[[149  13]\n",
            " [ 28 142]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       162\n",
            "           1       0.92      0.84      0.87       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPXmbiRIuyEG",
        "colab_type": "text"
      },
      "source": [
        "fourth round evaluation in validation\n",
        "\n",
        "When c=0.05 and 0.11, the score is 0.88, when c =0.08 and 0.13, the score is 0.877\n",
        "\n",
        "Choose 0.11 sent to test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0xOi4iuyEH",
        "colab_type": "code",
        "outputId": "c386dcd2-92ae-47a1-9e28-af39ffb8137a",
        "colab": {}
      },
      "source": [
        "# Evaluate linear kernel in test set\n",
        "svclassifier_lin = SVC(kernel='linear')\n",
        "svclassifier_lin.fit(X_train, y_train)\n",
        "# Doin predictions\n",
        "y_lin_pred = svclassifier_lin.predict(X_test)\n",
        "# result\n",
        "s_lin = round(svclassifier_lin.score(X_test, y_test), 3)\n",
        "c_lin = confusion_matrix(y_test, y_lin_pred)\n",
        "cr_lin = classification_report(y_test, y_lin_pred)\n",
        "print(\"the score is {0}, the confusion matrix is \\n{1}, the report is\\n {2}\".format(s_lin, c_lin, cr_lin))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the score is 0.872, the confusion matrix is \n",
            "[[163  18]\n",
            " [ 27 144]], the report is\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88       181\n",
            "           1       0.89      0.84      0.86       171\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       352\n",
            "   macro avg       0.87      0.87      0.87       352\n",
            "weighted avg       0.87      0.87      0.87       352\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndt-xBd2uyEI",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "default parameter on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQbv0GtHuyEJ",
        "colab_type": "code",
        "outputId": "0c8d2aad-0bf2-4c95-c7b2-2facddce8c59",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_test)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_test, y_test),3))\n",
        "print(confusion_matrix(y_test, y_rfc_pred))\n",
        "print(classification_report(y_test, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.841\n",
            "[[161  20]\n",
            " [ 36 135]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       181\n",
            "           1       0.87      0.79      0.83       171\n",
            "\n",
            "   micro avg       0.84      0.84      0.84       352\n",
            "   macro avg       0.84      0.84      0.84       352\n",
            "weighted avg       0.84      0.84      0.84       352\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZSUzn2uyEM",
        "colab_type": "code",
        "outputId": "405e6a9e-b539-4ece-b771-3620ab2783e7",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [2**int(x) for x in np.linspace(start = 1, stop = 11, num = 11)]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2**int(x) for x in np.linspace(1, 7, num = 7)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [x for x in np.linspace(0.1, 1, num = 10)]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [x for x in np.linspace(0.1, 0.5, num = 5)]\n",
        "# criterion\n",
        "criterion=['gini', 'entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "#rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_random.fit(X_train, y_train)\n",
        "print(rfc_random.best_estimator_, '\\n',rfc_random.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:    8.6s\n",
            "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   24.6s\n",
            "[Parallel(n_jobs=-1)]: Done 779 tasks      | elapsed:   46.9s\n",
            "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1485 out of 1500 | elapsed:  1.5min remaining:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  1.5min finished\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=0.1, min_samples_split=0.4,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=512, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.826271186440678\n",
            "It cost 92.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LsjB7PIuyEP",
        "colab_type": "code",
        "outputId": "431a063a-193f-4bff-bcbe-d7425e3665c9",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='entropy',max_depth=4,min_samples_leaf=0.1, min_samples_split=0.5,n_estimators=512)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_valid)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_valid, y_valid),3))\n",
        "print(confusion_matrix(y_valid, y_rfc_pred))\n",
        "print(classification_report(y_valid, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.798\n",
            "[[139  23]\n",
            " [ 44 126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81       162\n",
            "           1       0.85      0.74      0.79       170\n",
            "\n",
            "   micro avg       0.80      0.80      0.80       332\n",
            "   macro avg       0.80      0.80      0.80       332\n",
            "weighted avg       0.80      0.80      0.80       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "322FW1wUuyEQ",
        "colab_type": "code",
        "outputId": "e99ca049-a5ed-424d-ccdc-28aca1056b2b",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [2**int(x) for x in np.linspace(start = 1, stop = 11, num = 11)]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2**int(x) for x in np.linspace(1, 7, num = 7)]\n",
        "# Minimum number of samples required to split a node\n",
        "#min_samples_split = [x for x in np.linspace(0.1, 1, num = 10)]\n",
        "min_samples_split = [0.4, 0.5]\n",
        "# Minimum number of samples required at each leaf node\n",
        "#min_samples_leaf = [x for x in np.linspace(0.1, 0.5, num = 5)]\n",
        "min_samples_leaf= [0.1]\n",
        "# criterion\n",
        "criterion=['gini', 'entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "print(rfc_random.best_estimator_, '\\n',rfc_random.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #275s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=0.1, min_samples_split=0.5,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=512, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.8238498789346247\n",
            "It cost 257.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CADm97eEuyES",
        "colab_type": "code",
        "outputId": "b2ef0205-5eed-4955-ea3f-50fbf063b5b0",
        "colab": {}
      },
      "source": [
        "rfc_grid.cv_results_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.04256026, 0.08276916, 0.16921449, 0.32447433, 0.03958027,\n",
              "        0.07645853, 0.15225649, 0.30251582, 0.03823129, 0.07413578,\n",
              "        0.1466109 , 0.29288483, 0.03690076, 0.07347139, 0.14328154,\n",
              "        0.28423707, 0.03855975, 0.07513205, 0.14994391, 0.29721999,\n",
              "        0.03756436, 0.07280382, 0.14527798, 0.28723208, 0.03689949,\n",
              "        0.07114355, 0.1409595 , 0.28290931, 0.03590838, 0.06948185,\n",
              "        0.13796504, 0.27792247, 0.03556355, 0.07014759, 0.13830018,\n",
              "        0.27858822, 0.03557046, 0.06815044, 0.13628856, 0.26894895,\n",
              "        0.03424255, 0.06748382, 0.1329786 , 0.26429478, 0.0342416 ,\n",
              "        0.06682205, 0.13131595, 0.26097083, 0.0405581 , 0.07978733,\n",
              "        0.15824525, 0.31283172, 0.03889688, 0.07612673, 0.15092993,\n",
              "        0.30252632, 0.037896  , 0.07413761, 0.14726988, 0.29288642,\n",
              "        0.0369037 , 0.07247138, 0.14328663, 0.28424406, 0.03823169,\n",
              "        0.07480065, 0.14760605, 0.29687238, 0.03723335, 0.07347274,\n",
              "        0.14394991, 0.28789663, 0.03723534, 0.07147471, 0.14062341,\n",
              "        0.28158228, 0.03590433, 0.07080777, 0.13929407, 0.27626212,\n",
              "        0.03557309, 0.06948288, 0.13829645, 0.27360185, 0.03457443,\n",
              "        0.06848145, 0.13829525, 0.27193936, 0.03490623, 0.06781872,\n",
              "        0.13364291, 0.26564542, 0.03391004, 0.0664889 , 0.13164902,\n",
              "        0.26561459, 0.04488007, 0.08809773, 0.17486564, 0.35305603,\n",
              "        0.04321774, 0.08444118, 0.16755184, 0.33310938, 0.04255287,\n",
              "        0.0824461 , 0.16256539, 0.32546314, 0.04122321, 0.08045173,\n",
              "        0.15824334, 0.3161548 , 0.04288514, 0.08311121, 0.16456016,\n",
              "        0.32911984, 0.04155572, 0.08144879, 0.16023827, 0.32080897,\n",
              "        0.04122321, 0.07912191, 0.15824342, 0.31382751, 0.03989355,\n",
              "        0.07547402, 0.14627647, 0.28390733, 0.0388852 , 0.07779201,\n",
              "        0.15392168, 0.30385431, 0.03956087, 0.07679486, 0.15126228,\n",
              "        0.30152718, 0.038896  , 0.07513229, 0.14926759, 0.29720537,\n",
              "        0.03823113, 0.07413522, 0.1479377 , 0.30152639]),\n",
              " 'std_fit_time': array([9.56623689e-04, 1.39860114e-03, 1.36779619e-02, 1.17969670e-02,\n",
              "        9.22566832e-04, 4.70077941e-04, 1.24139430e-03, 1.24525427e-03,\n",
              "        4.71427042e-04, 4.72047272e-04, 8.14402092e-04, 2.05051761e-03,\n",
              "        8.48537942e-07, 1.24543002e-03, 1.24727956e-03, 8.18289389e-04,\n",
              "        9.42687652e-04, 4.69740686e-04, 9.44069825e-04, 8.01118309e-04,\n",
              "        4.68562545e-04, 2.83663564e-06, 4.69853077e-04, 1.62839746e-03,\n",
              "        2.73460556e-06, 4.71258123e-04, 4.67671803e-04, 1.24290201e-03,\n",
              "        8.16343644e-04, 4.70366725e-04, 9.39931240e-04, 3.08325336e-03,\n",
              "        4.64940695e-04, 4.68960248e-04, 4.75106237e-04, 6.16951392e-03,\n",
              "        4.72269527e-04, 9.41673113e-04, 4.61154634e-04, 4.72170097e-04,\n",
              "        4.69740928e-04, 4.67454524e-04, 9.37964312e-04, 8.14105490e-04,\n",
              "        4.70078667e-04, 8.12455962e-04, 4.70021655e-04, 2.48871405e-03,\n",
              "        4.70529118e-04, 7.86741172e-07, 1.24175517e-03, 1.24396574e-03,\n",
              "        6.25769923e-07, 4.72438164e-04, 4.69853077e-04, 9.35547828e-04,\n",
              "        3.60179558e-06, 4.67043774e-04, 4.90388026e-04, 4.68288092e-04,\n",
              "        4.35435852e-06, 4.68843250e-04, 4.68467749e-04, 1.63160968e-03,\n",
              "        4.70302724e-04, 8.16632194e-04, 8.15172155e-04, 1.24171724e-03,\n",
              "        4.72218597e-04, 4.70191058e-04, 1.24593940e-03, 9.39537552e-04,\n",
              "        4.67950923e-04, 4.70473799e-04, 8.10467325e-07, 2.04457482e-03,\n",
              "        3.04288701e-06, 1.40849214e-03, 9.40605267e-04, 1.62859230e-03,\n",
              "        4.71269582e-04, 4.70417291e-04, 9.39312809e-04, 1.69518596e-03,\n",
              "        4.67101461e-04, 4.68340676e-04, 9.18645902e-04, 2.48658982e-03,\n",
              "        2.97360213e-07, 8.14783749e-04, 1.41124511e-03, 5.02447771e-04,\n",
              "        7.01885292e-07, 4.70978200e-04, 8.14199157e-04, 5.40888385e-03,\n",
              "        8.14490730e-04, 4.70246438e-04, 1.69531061e-03, 1.27977785e-02,\n",
              "        4.70134046e-04, 1.69506124e-03, 8.14393390e-04, 1.41057073e-03,\n",
              "        4.70134046e-04, 4.70190252e-04, 1.41045834e-03, 4.70134046e-04,\n",
              "        4.70077860e-04, 4.70190252e-04, 1.24385777e-03, 2.15449843e-03,\n",
              "        1.12391596e-07, 4.70077860e-04, 1.62878678e-03, 2.44298550e-03,\n",
              "        4.70077860e-04, 4.70190252e-04, 1.24394273e-03, 2.48805539e-03,\n",
              "        4.70077860e-04, 4.70302644e-04, 4.70021655e-04, 2.61763596e-03,\n",
              "        1.12391596e-07, 4.48548899e-03, 6.78197499e-03, 8.78242272e-03,\n",
              "        2.43257626e-03, 1.12391596e-07, 9.40268092e-04, 2.48773678e-03,\n",
              "        9.40155701e-04, 1.41040214e-03, 1.24394273e-03, 2.48773678e-03,\n",
              "        1.12391596e-07, 4.70246438e-04, 4.70134086e-04, 8.14296085e-04,\n",
              "        4.70190252e-04, 4.70077860e-04, 9.40324293e-04, 7.52113321e-03]),\n",
              " 'mean_score_time': array([0.00498565, 0.00832065, 0.01528271, 0.02925515, 0.00465457,\n",
              "        0.00731452, 0.01462849, 0.02826746, 0.00398882, 0.00764441,\n",
              "        0.01429296, 0.02759147, 0.00432165, 0.00764632, 0.01429478,\n",
              "        0.02726205, 0.00432221, 0.00764879, 0.01429232, 0.02825435,\n",
              "        0.00432221, 0.00731365, 0.01396378, 0.02726102, 0.00432142,\n",
              "        0.00797939, 0.01429296, 0.02725943, 0.00398771, 0.00797701,\n",
              "        0.01396386, 0.02693081, 0.00399955, 0.00698153, 0.01394979,\n",
              "        0.02725983, 0.00398946, 0.00764624, 0.01397379, 0.02659488,\n",
              "        0.00398954, 0.00698026, 0.01396124, 0.02626061, 0.00398906,\n",
              "        0.00698002, 0.01329843, 0.02692628, 0.0043211 , 0.00797804,\n",
              "        0.01496005, 0.02892327, 0.00465536, 0.00798043, 0.01462857,\n",
              "        0.02825801, 0.00432173, 0.00731095, 0.01496077, 0.02759131,\n",
              "        0.00398644, 0.0076464 , 0.01429216, 0.02758932, 0.0039889 ,\n",
              "        0.00764497, 0.01429335, 0.02825634, 0.00465242, 0.00698129,\n",
              "        0.0142959 , 0.02759266, 0.00398755, 0.0073146 , 0.0142955 ,\n",
              "        0.0275894 , 0.00432062, 0.00731357, 0.01397181, 0.02692835,\n",
              "        0.00398835, 0.00697915, 0.01396243, 0.02726054, 0.0046521 ,\n",
              "        0.00764775, 0.014304  , 0.02692747, 0.00432674, 0.00731349,\n",
              "        0.01396529, 0.02626355, 0.00399288, 0.00730292, 0.01396171,\n",
              "        0.02659496, 0.00465409, 0.00797852, 0.01595743, 0.0302523 ,\n",
              "        0.00432165, 0.0079786 , 0.01562476, 0.02958735, 0.00432181,\n",
              "        0.00797876, 0.01529241, 0.02925499, 0.00398922, 0.00797868,\n",
              "        0.01495997, 0.02892248, 0.00398922, 0.00831103, 0.01529241,\n",
              "        0.02958751, 0.00498652, 0.00797884, 0.01529241, 0.02958743,\n",
              "        0.00432158, 0.00797852, 0.01462746, 0.02958759, 0.00432165,\n",
              "        0.00797828, 0.0152909 , 0.0269285 , 0.00498756, 0.00797876,\n",
              "        0.01462762, 0.02859012, 0.00465417, 0.00797852, 0.01495973,\n",
              "        0.0285902 , 0.00432181, 0.00764624, 0.01462754, 0.02859012,\n",
              "        0.00432165, 0.00731365, 0.01462762, 0.02825753]),\n",
              " 'std_score_time': array([1.91065713e-06, 4.82946727e-04, 4.77002129e-04, 4.70358829e-04,\n",
              "        4.69291200e-04, 4.70809402e-04, 4.71597708e-04, 4.61054616e-04,\n",
              "        5.94720425e-07, 4.71539755e-04, 4.71716566e-04, 4.69012110e-04,\n",
              "        4.69965550e-04, 4.69515983e-04, 4.70753901e-04, 4.68790238e-04,\n",
              "        4.70583774e-04, 4.71939097e-04, 4.69973935e-04, 4.71316419e-04,\n",
              "        4.69404318e-04, 4.69066336e-04, 1.96925985e-06, 4.70190252e-04,\n",
              "        4.71314972e-04, 2.29510134e-06, 4.73746576e-04, 4.70475248e-04,\n",
              "        4.44053492e-06, 2.86763804e-06, 2.94800393e-06, 4.53622284e-06,\n",
              "        1.49683497e-05, 5.94720425e-07, 1.40165433e-05, 4.72720496e-04,\n",
              "        0.00000000e+00, 4.70639899e-04, 1.28780368e-05, 4.71876206e-04,\n",
              "        6.83651389e-07, 8.10467325e-07, 1.63258223e-06, 4.68844463e-04,\n",
              "        3.14696469e-06, 3.40158694e-06, 4.69740766e-04, 4.93628189e-06,\n",
              "        4.70864602e-04, 9.19964862e-07, 0.00000000e+00, 1.18411894e-06,\n",
              "        4.71201776e-04, 2.65729483e-06, 4.68794441e-04, 4.72952850e-04,\n",
              "        4.70752210e-04, 4.68619681e-04, 1.21570099e-06, 9.37964191e-04,\n",
              "        3.59653107e-06, 4.70077941e-04, 4.72609909e-04, 4.67498204e-04,\n",
              "        5.94720425e-07, 4.72269527e-04, 4.69742945e-04, 4.68560928e-04,\n",
              "        4.69628375e-04, 1.57348234e-06, 4.70808396e-04, 4.70527427e-04,\n",
              "        3.71402786e-06, 4.70246800e-04, 4.69909424e-04, 4.74967244e-04,\n",
              "        4.70531856e-04, 4.70134086e-04, 1.31512576e-05, 1.65563159e-06,\n",
              "        4.03828494e-06, 2.41837884e-06, 4.89903609e-07, 4.69684520e-04,\n",
              "        4.68233749e-04, 4.67324297e-04, 4.83283863e-04, 3.89335909e-07,\n",
              "        4.72612435e-04, 4.69684480e-04, 2.62861815e-06, 4.69459737e-04,\n",
              "        3.29405177e-06, 4.76615629e-04, 8.10467325e-07, 9.40661589e-04,\n",
              "        4.70134046e-04, 1.12391596e-07, 1.12391596e-07, 4.70471221e-04,\n",
              "        4.70134086e-04, 1.12391596e-07, 4.70190252e-04, 4.70246438e-04,\n",
              "        4.70358829e-04, 1.12391596e-07, 4.70190252e-04, 4.70302644e-04,\n",
              "        0.00000000e+00, 1.94667955e-07, 1.12391596e-07, 1.12391596e-07,\n",
              "        1.94667955e-07, 4.70358829e-04, 4.70358829e-04, 4.70190252e-04,\n",
              "        1.94667955e-07, 1.12391596e-07, 4.70358829e-04, 4.70302644e-04,\n",
              "        4.70021655e-04, 1.12391596e-07, 4.70190252e-04, 4.70415035e-04,\n",
              "        4.70134046e-04, 7.86741172e-07, 1.24415556e-03, 2.24783192e-07,\n",
              "        1.63258223e-06, 1.12391596e-07, 4.70302644e-04, 4.70134046e-04,\n",
              "        4.70190252e-04, 1.12391596e-07, 1.12391596e-07, 4.70190252e-04,\n",
              "        4.70358829e-04, 4.70302644e-04, 4.70077941e-04, 4.70134086e-04,\n",
              "        4.70134046e-04, 4.70077860e-04, 4.70134086e-04, 4.70246438e-04]),\n",
              " 'param_criterion': masked_array(data=['entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
              "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_depth': masked_array(data=[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
              "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
              "                    32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
              "                    32, 32, 32, 32, 32, 32, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 64, 64,\n",
              "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
              "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
              "                    64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
              "                    64, 64, 64, 64],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
              "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "                    4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                    1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                    2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_min_samples_split': masked_array(data=[8, 8, 8, 8, 12, 12, 12, 12, 16, 16, 16, 16, 20, 20, 20,\n",
              "                    20, 8, 8, 8, 8, 12, 12, 12, 12, 16, 16, 16, 16, 20, 20,\n",
              "                    20, 20, 8, 8, 8, 8, 12, 12, 12, 12, 16, 16, 16, 16, 20,\n",
              "                    20, 20, 20, 8, 8, 8, 8, 12, 12, 12, 12, 16, 16, 16, 16,\n",
              "                    20, 20, 20, 20, 8, 8, 8, 8, 12, 12, 12, 12, 16, 16, 16,\n",
              "                    16, 20, 20, 20, 20, 8, 8, 8, 8, 12, 12, 12, 12, 16, 16,\n",
              "                    16, 16, 20, 20, 20, 20, 8, 8, 8, 8, 12, 12, 12, 12, 16,\n",
              "                    16, 16, 16, 20, 20, 20, 20, 8, 8, 8, 8, 12, 12, 12, 12,\n",
              "                    16, 16, 16, 16, 20, 20, 20, 20, 8, 8, 8, 8, 12, 12, 12,\n",
              "                    12, 16, 16, 16, 16, 20, 20, 20, 20],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_n_estimators': masked_array(data=[40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320,\n",
              "                    40, 80, 160, 320, 40, 80, 160, 320, 40, 80, 160, 320],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 32,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 50,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 1,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 2,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 8,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 12,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 16,\n",
              "   'n_estimators': 320},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 40},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 80},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 160},\n",
              "  {'criterion': 'entropy',\n",
              "   'max_depth': 64,\n",
              "   'min_samples_leaf': 4,\n",
              "   'min_samples_split': 20,\n",
              "   'n_estimators': 320}],\n",
              " 'split0_test_score': array([0.86413043, 0.85507246, 0.86413043, 0.87137681, 0.86775362,\n",
              "        0.85507246, 0.85688406, 0.86775362, 0.86594203, 0.85688406,\n",
              "        0.86956522, 0.86775362, 0.86413043, 0.86050725, 0.85688406,\n",
              "        0.86413043, 0.86594203, 0.86775362, 0.86231884, 0.86594203,\n",
              "        0.87681159, 0.86956522, 0.86413043, 0.87137681, 0.86231884,\n",
              "        0.86594203, 0.86956522, 0.86956522, 0.86231884, 0.86050725,\n",
              "        0.86413043, 0.86956522, 0.84963768, 0.86956522, 0.87318841,\n",
              "        0.86050725, 0.86050725, 0.88224638, 0.86050725, 0.86594203,\n",
              "        0.85688406, 0.86413043, 0.86413043, 0.86050725, 0.8442029 ,\n",
              "        0.86413043, 0.86775362, 0.86594203, 0.84782609, 0.86231884,\n",
              "        0.86594203, 0.86775362, 0.86231884, 0.86050725, 0.86594203,\n",
              "        0.86594203, 0.85869565, 0.86231884, 0.86775362, 0.86594203,\n",
              "        0.86050725, 0.86413043, 0.86775362, 0.86594203, 0.86594203,\n",
              "        0.87318841, 0.86775362, 0.86956522, 0.87137681, 0.87137681,\n",
              "        0.87318841, 0.86956522, 0.86594203, 0.86413043, 0.86413043,\n",
              "        0.86956522, 0.86413043, 0.85507246, 0.86594203, 0.86050725,\n",
              "        0.86413043, 0.85869565, 0.86594203, 0.86775362, 0.85507246,\n",
              "        0.86050725, 0.86050725, 0.86050725, 0.85507246, 0.85869565,\n",
              "        0.86775362, 0.86594203, 0.87681159, 0.85869565, 0.86050725,\n",
              "        0.86231884, 0.86413043, 0.86413043, 0.85688406, 0.87137681,\n",
              "        0.86956522, 0.86594203, 0.86413043, 0.86231884, 0.84963768,\n",
              "        0.86956522, 0.86775362, 0.86594203, 0.86956522, 0.86231884,\n",
              "        0.85869565, 0.86594203, 0.86050725, 0.87318841, 0.86775362,\n",
              "        0.86594203, 0.86413043, 0.86413043, 0.85507246, 0.86956522,\n",
              "        0.8442029 , 0.86231884, 0.86413043, 0.87137681, 0.87318841,\n",
              "        0.86413043, 0.86956522, 0.86231884, 0.8442029 , 0.86050725,\n",
              "        0.85869565, 0.87137681, 0.87318841, 0.86231884, 0.86956522,\n",
              "        0.86775362, 0.85869565, 0.86594203, 0.86413043, 0.86413043,\n",
              "        0.86775362, 0.85869565, 0.86413043, 0.86231884]),\n",
              " 'split1_test_score': array([0.88      , 0.88545455, 0.88545455, 0.88      , 0.87818182,\n",
              "        0.86909091, 0.87818182, 0.87454545, 0.86      , 0.87454545,\n",
              "        0.88      , 0.88181818, 0.87272727, 0.87272727, 0.88545455,\n",
              "        0.87636364, 0.88363636, 0.88      , 0.87272727, 0.87818182,\n",
              "        0.86      , 0.88      , 0.87818182, 0.88      , 0.86727273,\n",
              "        0.87818182, 0.88545455, 0.87090909, 0.87636364, 0.87090909,\n",
              "        0.87272727, 0.88181818, 0.88545455, 0.88      , 0.87636364,\n",
              "        0.88181818, 0.86727273, 0.86727273, 0.87636364, 0.88363636,\n",
              "        0.87454545, 0.88363636, 0.88181818, 0.87454545, 0.87636364,\n",
              "        0.87272727, 0.88545455, 0.88      , 0.86909091, 0.88181818,\n",
              "        0.87636364, 0.88363636, 0.87636364, 0.87636364, 0.88181818,\n",
              "        0.88545455, 0.87090909, 0.87090909, 0.87272727, 0.87636364,\n",
              "        0.88545455, 0.88363636, 0.87636364, 0.88909091, 0.87454545,\n",
              "        0.88181818, 0.88      , 0.87818182, 0.87272727, 0.87272727,\n",
              "        0.88363636, 0.88181818, 0.87454545, 0.87090909, 0.87818182,\n",
              "        0.88363636, 0.88      , 0.88545455, 0.87272727, 0.86909091,\n",
              "        0.88181818, 0.88      , 0.86909091, 0.88909091, 0.85818182,\n",
              "        0.88363636, 0.87636364, 0.87636364, 0.87454545, 0.87818182,\n",
              "        0.88727273, 0.88727273, 0.86909091, 0.88727273, 0.88727273,\n",
              "        0.88545455, 0.88181818, 0.87636364, 0.87818182, 0.88181818,\n",
              "        0.87818182, 0.88      , 0.88      , 0.87454545, 0.87454545,\n",
              "        0.87272727, 0.87818182, 0.88363636, 0.88181818, 0.87818182,\n",
              "        0.88      , 0.87636364, 0.86909091, 0.87818182, 0.87636364,\n",
              "        0.87818182, 0.87818182, 0.87818182, 0.88181818, 0.88909091,\n",
              "        0.87818182, 0.87636364, 0.88727273, 0.88363636, 0.87272727,\n",
              "        0.88      , 0.88363636, 0.88181818, 0.87272727, 0.88363636,\n",
              "        0.87636364, 0.88363636, 0.87636364, 0.88363636, 0.87818182,\n",
              "        0.88545455, 0.87090909, 0.88181818, 0.88181818, 0.88      ,\n",
              "        0.86727273, 0.88      , 0.87454545, 0.89090909]),\n",
              " 'split2_test_score': array([0.85636364, 0.86181818, 0.86      , 0.85818182, 0.86181818,\n",
              "        0.86      , 0.86545455, 0.86      , 0.85454545, 0.85636364,\n",
              "        0.86      , 0.85818182, 0.86      , 0.87090909, 0.86909091,\n",
              "        0.86181818, 0.86      , 0.86545455, 0.86181818, 0.85636364,\n",
              "        0.86909091, 0.86363636, 0.85818182, 0.86181818, 0.86181818,\n",
              "        0.85818182, 0.86181818, 0.86181818, 0.85636364, 0.87272727,\n",
              "        0.86545455, 0.85818182, 0.87272727, 0.85818182, 0.86727273,\n",
              "        0.85090909, 0.86      , 0.85818182, 0.86      , 0.85454545,\n",
              "        0.85090909, 0.86      , 0.85636364, 0.86      , 0.85818182,\n",
              "        0.86363636, 0.86909091, 0.86      , 0.85272727, 0.85454545,\n",
              "        0.86181818, 0.86727273, 0.85454545, 0.87636364, 0.86727273,\n",
              "        0.86545455, 0.86909091, 0.85636364, 0.85454545, 0.86363636,\n",
              "        0.86363636, 0.85454545, 0.86727273, 0.85818182, 0.86      ,\n",
              "        0.87272727, 0.85636364, 0.86      , 0.86181818, 0.86181818,\n",
              "        0.85636364, 0.86545455, 0.86363636, 0.86      , 0.85636364,\n",
              "        0.85636364, 0.86909091, 0.86727273, 0.86363636, 0.86      ,\n",
              "        0.85090909, 0.85454545, 0.85272727, 0.85636364, 0.85818182,\n",
              "        0.85818182, 0.86181818, 0.85818182, 0.86363636, 0.86363636,\n",
              "        0.86545455, 0.86      , 0.87272727, 0.86909091, 0.86909091,\n",
              "        0.86363636, 0.85818182, 0.86181818, 0.86545455, 0.86181818,\n",
              "        0.85636364, 0.86181818, 0.86545455, 0.86181818, 0.85454545,\n",
              "        0.86181818, 0.86363636, 0.85818182, 0.85454545, 0.86363636,\n",
              "        0.86727273, 0.86545455, 0.86363636, 0.86727273, 0.86363636,\n",
              "        0.85818182, 0.87454545, 0.86545455, 0.85818182, 0.85636364,\n",
              "        0.87454545, 0.87090909, 0.86      , 0.86      , 0.85818182,\n",
              "        0.85272727, 0.87636364, 0.86363636, 0.85818182, 0.87636364,\n",
              "        0.85818182, 0.86545455, 0.86      , 0.85454545, 0.85636364,\n",
              "        0.85818182, 0.84909091, 0.85272727, 0.86181818, 0.86181818,\n",
              "        0.86181818, 0.85818182, 0.85818182, 0.86181818]),\n",
              " 'mean_test_score': array([0.86682809, 0.86743341, 0.86985472, 0.86985472, 0.86924939,\n",
              "        0.86138015, 0.86682809, 0.86743341, 0.86016949, 0.8625908 ,\n",
              "        0.86985472, 0.86924939, 0.86561743, 0.86803874, 0.87046005,\n",
              "        0.86743341, 0.86985472, 0.87106538, 0.86561743, 0.86682809,\n",
              "        0.86864407, 0.87106538, 0.86682809, 0.87106538, 0.86380145,\n",
              "        0.86743341, 0.87227603, 0.86743341, 0.86501211, 0.86803874,\n",
              "        0.86743341, 0.86985472, 0.86924939, 0.86924939, 0.87227603,\n",
              "        0.86440678, 0.8625908 , 0.86924939, 0.86561743, 0.86803874,\n",
              "        0.86077482, 0.86924939, 0.86743341, 0.86501211, 0.85956416,\n",
              "        0.86682809, 0.87409201, 0.86864407, 0.85653753, 0.86622276,\n",
              "        0.86803874, 0.87288136, 0.86440678, 0.87106538, 0.8716707 ,\n",
              "        0.87227603, 0.86622276, 0.86319613, 0.86501211, 0.86864407,\n",
              "        0.86985472, 0.86743341, 0.87046005, 0.87106538, 0.86682809,\n",
              "        0.87590799, 0.86803874, 0.86924939, 0.86864407, 0.86864407,\n",
              "        0.87106538, 0.87227603, 0.86803874, 0.86501211, 0.86622276,\n",
              "        0.86985472, 0.87106538, 0.86924939, 0.86743341, 0.86319613,\n",
              "        0.86561743, 0.86440678, 0.8625908 , 0.87106538, 0.85714286,\n",
              "        0.86743341, 0.86622276, 0.86501211, 0.86440678, 0.86682809,\n",
              "        0.87348668, 0.87106538, 0.87288136, 0.8716707 , 0.87227603,\n",
              "        0.87046005, 0.86803874, 0.86743341, 0.86682809, 0.8716707 ,\n",
              "        0.86803874, 0.86924939, 0.86985472, 0.86622276, 0.85956416,\n",
              "        0.86803874, 0.86985472, 0.86924939, 0.86864407, 0.86803874,\n",
              "        0.86864407, 0.86924939, 0.86440678, 0.87288136, 0.86924939,\n",
              "        0.86743341, 0.87227603, 0.86924939, 0.86501211, 0.8716707 ,\n",
              "        0.86561743, 0.86985472, 0.87046005, 0.8716707 , 0.86803874,\n",
              "        0.86561743, 0.87651332, 0.86924939, 0.85835351, 0.87348668,\n",
              "        0.86440678, 0.87348668, 0.86985472, 0.86682809, 0.86803874,\n",
              "        0.87046005, 0.85956416, 0.86682809, 0.86924939, 0.86864407,\n",
              "        0.86561743, 0.86561743, 0.86561743, 0.8716707 ]),\n",
              " 'std_test_score': array([0.00983118, 0.01302592, 0.01114906, 0.0089669 , 0.00675994,\n",
              "        0.00580717, 0.00875135, 0.00593889, 0.00465557, 0.00844822,\n",
              "        0.0081626 , 0.0097017 , 0.00529851, 0.00538657, 0.01170739,\n",
              "        0.00637916, 0.01003407, 0.00638144, 0.00502701, 0.00892394,\n",
              "        0.00687262, 0.00676043, 0.0083808 , 0.00742148, 0.00246084,\n",
              "        0.00822813, 0.009833  , 0.00400475, 0.00838009, 0.00538657,\n",
              "        0.00377881, 0.00964584, 0.0148315 , 0.00890465, 0.00376499,\n",
              "        0.01290995, 0.0033141 , 0.00992599, 0.00759464, 0.0119617 ,\n",
              "        0.01002979, 0.0103029 , 0.01064579, 0.00673816, 0.01316978,\n",
              "        0.00417245, 0.00804579, 0.00838151, 0.00909157, 0.01146581,\n",
              "        0.00611761, 0.00760057, 0.00902388, 0.00747929, 0.0071894 ,\n",
              "        0.00931229, 0.00538349, 0.00596701, 0.0076682 , 0.00553429,\n",
              "        0.01109456, 0.01209755, 0.0041753 , 0.0131228 , 0.00596766,\n",
              "        0.00417959, 0.00964578, 0.00742157, 0.00485368, 0.00485368,\n",
              "        0.01122848, 0.00694706, 0.00469221, 0.00449453, 0.00902439,\n",
              "        0.01112919, 0.00662909, 0.0124855 , 0.00385663, 0.00416961,\n",
              "        0.01265486, 0.01114567, 0.00708589, 0.01355729, 0.00146665,\n",
              "        0.01148614, 0.00718415, 0.00807549, 0.00797081, 0.00827088,\n",
              "        0.0097845 , 0.01170423, 0.00315478, 0.01181151, 0.01115947,\n",
              "        0.01060674, 0.01003322, 0.00637916, 0.00875135, 0.00816268,\n",
              "        0.00896728, 0.00777939, 0.00718765, 0.00588324, 0.01077185,\n",
              "        0.00458039, 0.00611836, 0.01064648, 0.01114642, 0.0071859 ,\n",
              "        0.00875386, 0.0050299 , 0.00354732, 0.00445623, 0.00529974,\n",
              "        0.00822813, 0.00595795, 0.00633357, 0.01194061, 0.01343581,\n",
              "        0.01524225, 0.00578366, 0.01199674, 0.00964591, 0.00696612,\n",
              "        0.01117705, 0.00574722, 0.00889569, 0.01164916, 0.00966147,\n",
              "        0.0084497 , 0.00756727, 0.00708174, 0.01229145, 0.00896728,\n",
              "        0.01129126, 0.00892308, 0.01188571, 0.00892947, 0.00807795,\n",
              "        0.00269121, 0.01016294, 0.00675897, 0.01359278]),\n",
              " 'rank_test_score': array([ 94,  82,  36,  36,  47, 136,  94,  82, 138, 133,  36,  47, 109,\n",
              "         70,  31,  82,  36,  22, 109,  94,  62,  22,  94,  22, 130,  82,\n",
              "         10,  82, 118,  70,  82,  36,  47,  47,  10, 124, 133,  47, 109,\n",
              "         70, 137,  47,  82, 118, 139,  94,   3,  62, 144, 104,  70,   7,\n",
              "        124,  22,  16,  10, 104, 131, 118,  62,  36,  82,  31,  22,  94,\n",
              "          2,  70,  47,  62,  62,  22,  10,  70, 118, 104,  36,  22,  47,\n",
              "         82, 131, 109, 124, 133,  22, 143,  82, 104, 118, 124,  94,   4,\n",
              "         22,   7,  16,  10,  31,  70,  82,  94,  16,  70,  47,  36, 104,\n",
              "        139,  70,  36,  47,  62,  70,  62,  47, 124,   7,  47,  82,  10,\n",
              "         47, 118,  16, 109,  36,  31,  16,  70, 109,   1,  47, 142,   4,\n",
              "        124,   4,  36,  94,  70,  31, 139,  94,  47,  62, 109, 109, 109,\n",
              "         16]),\n",
              " 'split0_train_score': array([0.97454545, 0.97909091, 0.97272727, 0.97727273, 0.95636364,\n",
              "        0.95545455, 0.95727273, 0.96181818, 0.95272727, 0.94272727,\n",
              "        0.95272727, 0.94636364, 0.93181818, 0.93      , 0.93181818,\n",
              "        0.93636364, 0.94818182, 0.94909091, 0.94909091, 0.95      ,\n",
              "        0.93454545, 0.94454545, 0.94181818, 0.94272727, 0.92818182,\n",
              "        0.93090909, 0.93090909, 0.93636364, 0.92818182, 0.92727273,\n",
              "        0.92909091, 0.92727273, 0.91636364, 0.92454545, 0.92545455,\n",
              "        0.92818182, 0.91272727, 0.91636364, 0.91818182, 0.91818182,\n",
              "        0.92090909, 0.91454545, 0.91727273, 0.91363636, 0.90909091,\n",
              "        0.90818182, 0.91181818, 0.91272727, 0.97636364, 0.97454545,\n",
              "        0.97272727, 0.97727273, 0.95363636, 0.95545455, 0.96272727,\n",
              "        0.95818182, 0.94363636, 0.94727273, 0.94909091, 0.94727273,\n",
              "        0.92727273, 0.93454545, 0.93909091, 0.93363636, 0.95272727,\n",
              "        0.94727273, 0.95      , 0.95090909, 0.93727273, 0.93727273,\n",
              "        0.93818182, 0.94      , 0.92545455, 0.93      , 0.93272727,\n",
              "        0.93363636, 0.92090909, 0.92454545, 0.92727273, 0.92909091,\n",
              "        0.91818182, 0.91636364, 0.92545455, 0.92818182, 0.91363636,\n",
              "        0.91909091, 0.91363636, 0.91909091, 0.91      , 0.91      ,\n",
              "        0.91636364, 0.91272727, 0.90636364, 0.91      , 0.91      ,\n",
              "        0.90636364, 0.97363636, 0.97454545, 0.97363636, 0.97181818,\n",
              "        0.95727273, 0.96181818, 0.96272727, 0.95909091, 0.94181818,\n",
              "        0.94636364, 0.95      , 0.95090909, 0.93363636, 0.93636364,\n",
              "        0.93181818, 0.93909091, 0.95090909, 0.94727273, 0.94727273,\n",
              "        0.95      , 0.93909091, 0.94272727, 0.94090909, 0.94090909,\n",
              "        0.92818182, 0.92636364, 0.93363636, 0.93090909, 0.92363636,\n",
              "        0.92454545, 0.92454545, 0.93272727, 0.91272727, 0.92      ,\n",
              "        0.91909091, 0.91818182, 0.91272727, 0.91454545, 0.91818182,\n",
              "        0.91909091, 0.91090909, 0.91181818, 0.91727273, 0.91272727,\n",
              "        0.90636364, 0.91181818, 0.91      , 0.90909091]),\n",
              " 'split1_train_score': array([0.97640653, 0.97912886, 0.97731397, 0.97912886, 0.95281307,\n",
              "        0.95916515, 0.96188748, 0.95825771, 0.94555354, 0.9491833 ,\n",
              "        0.94827586, 0.95462795, 0.93647913, 0.93829401, 0.94373866,\n",
              "        0.94192377, 0.95009074, 0.95735027, 0.95372051, 0.95553539,\n",
              "        0.93284936, 0.94101633, 0.94283122, 0.94101633, 0.93466425,\n",
              "        0.93375681, 0.93466425, 0.93738657, 0.92649728, 0.93194192,\n",
              "        0.93012704, 0.9292196 , 0.92558984, 0.93012704, 0.92558984,\n",
              "        0.92286751, 0.91651543, 0.92649728, 0.92105263, 0.92286751,\n",
              "        0.91470054, 0.92105263, 0.92196007, 0.91651543, 0.91288566,\n",
              "        0.91197822, 0.91560799, 0.91742287, 0.97912886, 0.97459165,\n",
              "        0.97822142, 0.98094374, 0.95553539, 0.96188748, 0.96098004,\n",
              "        0.95916515, 0.94555354, 0.95190563, 0.95190563, 0.95190563,\n",
              "        0.94192377, 0.94283122, 0.93829401, 0.94283122, 0.94646098,\n",
              "        0.95190563, 0.95372051, 0.95099819, 0.93557169, 0.94101633,\n",
              "        0.94646098, 0.94646098, 0.93466425, 0.93284936, 0.93829401,\n",
              "        0.93920145, 0.93012704, 0.93012704, 0.9292196 , 0.93466425,\n",
              "        0.9246824 , 0.92196007, 0.92014519, 0.92558984, 0.92105263,\n",
              "        0.92014519, 0.92014519, 0.92286751, 0.91288566, 0.91560799,\n",
              "        0.9137931 , 0.92105263, 0.91107078, 0.90834846, 0.91923775,\n",
              "        0.91833031, 0.97005445, 0.97277677, 0.97640653, 0.97549909,\n",
              "        0.95462795, 0.96188748, 0.96098004, 0.96098004, 0.9491833 ,\n",
              "        0.95190563, 0.95553539, 0.95190563, 0.94010889, 0.93920145,\n",
              "        0.94646098, 0.94736842, 0.93829401, 0.95281307, 0.95462795,\n",
              "        0.95462795, 0.94101633, 0.9446461 , 0.95009074, 0.94283122,\n",
              "        0.93012704, 0.9292196 , 0.93647913, 0.93738657, 0.92740472,\n",
              "        0.92558984, 0.93647913, 0.93466425, 0.92286751, 0.92286751,\n",
              "        0.92196007, 0.92558984, 0.91742287, 0.92649728, 0.92105263,\n",
              "        0.92377495, 0.91560799, 0.91833031, 0.91923775, 0.91470054,\n",
              "        0.91016334, 0.92014519, 0.91470054, 0.91923775]),\n",
              " 'split2_train_score': array([0.9800363 , 0.97368421, 0.97822142, 0.97640653, 0.94827586,\n",
              "        0.9600726 , 0.96098004, 0.96098004, 0.94192377, 0.94646098,\n",
              "        0.94283122, 0.94646098, 0.93375681, 0.93194192, 0.94283122,\n",
              "        0.93829401, 0.94555354, 0.95190563, 0.9491833 , 0.95281307,\n",
              "        0.93284936, 0.93557169, 0.94283122, 0.93557169, 0.93194192,\n",
              "        0.92649728, 0.9292196 , 0.93194192, 0.9246824 , 0.9246824 ,\n",
              "        0.92649728, 0.91833031, 0.91107078, 0.91107078, 0.91197822,\n",
              "        0.9137931 , 0.91560799, 0.9137931 , 0.91470054, 0.9137931 ,\n",
              "        0.89836661, 0.90834846, 0.90744102, 0.91107078, 0.90381125,\n",
              "        0.91016334, 0.90834846, 0.90834846, 0.97005445, 0.97731397,\n",
              "        0.97822142, 0.97731397, 0.96098004, 0.95190563, 0.95372051,\n",
              "        0.9600726 , 0.93647913, 0.94283122, 0.94373866, 0.9491833 ,\n",
              "        0.93466425, 0.93284936, 0.93466425, 0.93647913, 0.94101633,\n",
              "        0.94736842, 0.94646098, 0.94736842, 0.93103448, 0.93738657,\n",
              "        0.93284936, 0.93647913, 0.93284936, 0.93284936, 0.9292196 ,\n",
              "        0.93012704, 0.92014519, 0.92377495, 0.92649728, 0.92286751,\n",
              "        0.90562613, 0.9092559 , 0.9137931 , 0.91470054, 0.90834846,\n",
              "        0.91107078, 0.92014519, 0.91107078, 0.90471869, 0.90199637,\n",
              "        0.9092559 , 0.90562613, 0.90653358, 0.90018149, 0.90108893,\n",
              "        0.90834846, 0.97005445, 0.97549909, 0.97640653, 0.97640653,\n",
              "        0.95372051, 0.96188748, 0.95825771, 0.96188748, 0.95099819,\n",
              "        0.94010889, 0.94555354, 0.94192377, 0.93647913, 0.93012704,\n",
              "        0.93194192, 0.93557169, 0.9491833 , 0.95190563, 0.94373866,\n",
              "        0.95099819, 0.93375681, 0.93647913, 0.93466425, 0.93920145,\n",
              "        0.9292196 , 0.92740472, 0.93103448, 0.93012704, 0.91742287,\n",
              "        0.91833031, 0.92196007, 0.91833031, 0.9137931 , 0.91742287,\n",
              "        0.91470054, 0.91107078, 0.91107078, 0.90834846, 0.91016334,\n",
              "        0.91016334, 0.90471869, 0.90381125, 0.90834846, 0.90562613,\n",
              "        0.9092559 , 0.90199637, 0.90471869, 0.90744102]),\n",
              " 'mean_train_score': array([0.9769961 , 0.97730133, 0.97608755, 0.97760271, 0.95248419,\n",
              "        0.95823077, 0.96004675, 0.96035198, 0.94673486, 0.94612385,\n",
              "        0.94794478, 0.94915086, 0.93401804, 0.93341198, 0.93946268,\n",
              "        0.93886047, 0.94794203, 0.95278227, 0.95066491, 0.95278282,\n",
              "        0.93341473, 0.94037783, 0.94249354, 0.93977176, 0.931596  ,\n",
              "        0.93038772, 0.93159765, 0.93523071, 0.92645383, 0.92796568,\n",
              "        0.92857174, 0.92494088, 0.91767475, 0.92191443, 0.92100753,\n",
              "        0.92161415, 0.91495023, 0.91888467, 0.91797833, 0.91828081,\n",
              "        0.91132541, 0.91464885, 0.91555794, 0.91374086, 0.90859594,\n",
              "        0.91010779, 0.91192487, 0.91283287, 0.97518231, 0.97548369,\n",
              "        0.97639003, 0.97851015, 0.95671726, 0.95641588, 0.95914261,\n",
              "        0.95913986, 0.94188968, 0.94733652, 0.94824506, 0.94945389,\n",
              "        0.93462025, 0.93674201, 0.93734972, 0.9376489 , 0.94673486,\n",
              "        0.94884892, 0.9500605 , 0.94975857, 0.9346263 , 0.93855854,\n",
              "        0.93916405, 0.94098004, 0.93098939, 0.93189958, 0.93341363,\n",
              "        0.93432162, 0.92372711, 0.92614915, 0.9276632 , 0.92887422,\n",
              "        0.91616345, 0.91585987, 0.91979761, 0.92282407, 0.91434582,\n",
              "        0.91676896, 0.91797558, 0.9176764 , 0.90920145, 0.90920145,\n",
              "        0.91313755, 0.91313535, 0.90798933, 0.90617665, 0.91010889,\n",
              "        0.91101413, 0.97124842, 0.97427377, 0.97548314, 0.9745746 ,\n",
              "        0.95520706, 0.96186438, 0.96065501, 0.96065281, 0.94733322,\n",
              "        0.94612605, 0.95036298, 0.94824616, 0.93674146, 0.93523071,\n",
              "        0.93674036, 0.94067701, 0.9461288 , 0.95066381, 0.94854644,\n",
              "        0.95187538, 0.93795468, 0.94128417, 0.94188803, 0.94098059,\n",
              "        0.92917615, 0.92766265, 0.93371666, 0.93280757, 0.92282132,\n",
              "        0.92282187, 0.92766155, 0.92857394, 0.91646263, 0.92009679,\n",
              "        0.91858384, 0.91828081, 0.91374031, 0.91646373, 0.91646593,\n",
              "        0.9176764 , 0.91041192, 0.91131991, 0.91495298, 0.91101798,\n",
              "        0.90859429, 0.91131991, 0.90980641, 0.91192322]),\n",
              " 'std_train_score': array([2.28006238e-03, 2.55773338e-03, 2.40478433e-03, 1.13561293e-03,\n",
              "        3.30999941e-03, 1.99773347e-03, 1.99620494e-03, 1.51988549e-03,\n",
              "        4.48891482e-03, 2.64642192e-03, 4.04682547e-03, 3.87309419e-03,\n",
              "        1.91176861e-03, 3.54198148e-03, 5.41815978e-03, 2.30498672e-03,\n",
              "        1.86005016e-03, 3.42837640e-03, 2.16096568e-03, 2.25991480e-03,\n",
              "        7.99544378e-04, 3.69124117e-03, 4.77548879e-04, 3.05093570e-03,\n",
              "        2.65772079e-03, 2.98653134e-03, 2.27546684e-03, 2.36272221e-03,\n",
              "        1.42896356e-03, 3.00392267e-03, 1.52664054e-03, 4.74147016e-03,\n",
              "        5.99944526e-03, 7.99904199e-03, 6.38492742e-03, 5.94064965e-03,\n",
              "        1.61493255e-03, 5.48426404e-03, 2.59721746e-03, 3.70527370e-03,\n",
              "        9.50734925e-03, 5.18697268e-03, 6.05013077e-03, 2.22399519e-03,\n",
              "        3.72110869e-03, 1.55037274e-03, 2.96465003e-03, 3.70536479e-03,\n",
              "        3.79761972e-03, 1.29434154e-03, 2.58996379e-03, 1.72089166e-03,\n",
              "        3.11234105e-03, 4.13138117e-03, 3.89979190e-03, 7.72113772e-04,\n",
              "        3.90507492e-03, 3.70488708e-03, 3.38737230e-03, 1.90102588e-03,\n",
              "        5.98134608e-03, 4.36103856e-03, 1.92658514e-03, 3.84383539e-03,\n",
              "        4.78489153e-03, 2.16176726e-03, 2.96399865e-03, 1.69047883e-03,\n",
              "        2.63302656e-03, 1.73854148e-03, 5.60015525e-03, 4.13357727e-03,\n",
              "        3.98323918e-03, 1.34320344e-03, 3.73626754e-03, 3.73616659e-03,\n",
              "        4.53616963e-03, 2.83032775e-03, 1.14516768e-03, 4.81843289e-03,\n",
              "        7.90951467e-03, 5.19867591e-03, 4.76710359e-03, 5.84085034e-03,\n",
              "        5.21066242e-03, 4.05214475e-03, 3.06829044e-03, 4.91876363e-03,\n",
              "        3.38162738e-03, 5.58553350e-03, 2.93851453e-03, 6.30444803e-03,\n",
              "        2.18001820e-03, 4.29250189e-03, 7.40962496e-03, 5.23639093e-03,\n",
              "        1.68853195e-03, 1.12786499e-03, 1.30587063e-03, 1.98397818e-03,\n",
              "        1.50689382e-03, 3.26662100e-05, 1.83910727e-03, 1.16490556e-03,\n",
              "        3.96948455e-03, 4.81892543e-03, 4.08314847e-03, 4.48907734e-03,\n",
              "        2.64890201e-03, 3.79023936e-03, 6.87370066e-03, 4.94486307e-03,\n",
              "        5.58465429e-03, 2.42630416e-03, 4.53585257e-03, 1.98856381e-03,\n",
              "        3.07066166e-03, 3.48680971e-03, 6.33576840e-03, 1.48270709e-03,\n",
              "        7.94728221e-04, 1.18012154e-03, 2.22349248e-03, 3.25354650e-03,\n",
              "        4.11562587e-03, 3.20450243e-03, 6.32367489e-03, 7.28637989e-03,\n",
              "        4.54979121e-03, 2.22382097e-03, 2.98530009e-03, 5.92779321e-03,\n",
              "        2.69034463e-03, 7.53236373e-03, 4.60813600e-03, 5.64621656e-03,\n",
              "        4.45941348e-03, 5.93784201e-03, 4.73850176e-03, 3.89679196e-03,\n",
              "        1.62023221e-03, 7.41759722e-03, 4.07737214e-03, 5.21582455e-03])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXA4GO2suyEU",
        "colab_type": "code",
        "outputId": "2d644edc-1d7c-42c4-9078-8555292b2b18",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='entropy',max_depth=None,min_samples_leaf=1, min_samples_split=2,n_estimators=10)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_valid)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_valid, y_valid),3))\n",
        "print(confusion_matrix(y_valid, y_rfc_pred))\n",
        "print(classification_report(y_valid, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.855\n",
            "[[149  13]\n",
            " [ 35 135]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       162\n",
            "           1       0.91      0.79      0.85       170\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       332\n",
            "   macro avg       0.86      0.86      0.86       332\n",
            "weighted avg       0.86      0.86      0.86       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2DMwo8SuyEX",
        "colab_type": "text"
      },
      "source": [
        "follow by default parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XNLT9t7uyEX",
        "colab_type": "code",
        "outputId": "feb67680-c7b6-4b9c-805b-fcec4e41fe88",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [2, 6, 10, 20, 40, 80, 160, 320]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2, 8, 16, 32, 64, 128]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 8, 16, 32]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4, 8, 16]\n",
        "# criterion\n",
        "criterion=['gini', 'entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "#rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_random.fit(X_train, y_train)\n",
        "print(rfc_random.best_estimator_, '\\n',rfc_random.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=-1)]: Done 561 tasks      | elapsed:   15.8s\n",
            "[Parallel(n_jobs=-1)]: Done 1127 tasks      | elapsed:   25.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1477 out of 1500 | elapsed:   31.6s remaining:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:   32.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=32, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=2, min_samples_split=8,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=320, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.87409200968523\n",
            "It cost 32.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH7EROA2uyEY",
        "colab_type": "code",
        "outputId": "34f36b40-5884-419e-ec26-162a765e933c",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='gini',max_depth=32,min_samples_leaf=2, min_samples_split=8,n_estimators=320)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_valid)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_valid, y_valid),3))\n",
        "print(confusion_matrix(y_valid, y_rfc_pred))\n",
        "print(classification_report(y_valid, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.861\n",
            "[[145  17]\n",
            " [ 29 141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       162\n",
            "           1       0.89      0.83      0.86       170\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       332\n",
            "   macro avg       0.86      0.86      0.86       332\n",
            "weighted avg       0.86      0.86      0.86       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd_TGuBkuyEa",
        "colab_type": "code",
        "outputId": "4d391f7e-5654-4fd4-e06d-7ac9c980ad38",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [2, 6, 10, 20, 40, 80, 160, 320]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [2, 8, 16, 32, 64]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 8, 16]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# criterion\n",
        "criterion=['gini', 'entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "print(rfc_grid.best_estimator_, '\\n',rfc_grid.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=32, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=4, min_samples_split=16,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.8753026634382567\n",
            "It cost 176.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cCLBzYOuyEb",
        "colab_type": "code",
        "outputId": "e74f94d1-f755-4d21-dbc2-a96c621a1e48",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [40, 80, 160, 320]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [32,50,64]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [8, 12, 16, 20]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# criterion\n",
        "criterion=['entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "print(rfc_grid.best_estimator_, '\\n',rfc_grid.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=64, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=2, min_samples_split=20,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=160, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.8765133171912833\n",
            "It cost 75.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6NS1gFvuyEd",
        "colab_type": "code",
        "outputId": "39983848-6394-4f83-c3ac-c3b49593270a",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='entropy',max_depth=64,min_samples_leaf=2, min_samples_split=20,n_estimators=160)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_valid)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_valid, y_valid),3))\n",
        "print(confusion_matrix(y_valid, y_rfc_pred))\n",
        "print(classification_report(y_valid, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.87\n",
            "[[146  16]\n",
            " [ 27 143]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       162\n",
            "           1       0.90      0.84      0.87       170\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       332\n",
            "   macro avg       0.87      0.87      0.87       332\n",
            "weighted avg       0.87      0.87      0.87       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iKmVimmuyEf",
        "colab_type": "code",
        "outputId": "ca16fb56-e9e5-4ced-a5de-4475d647518a",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [80,100,130,160]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [50,55,60,64]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [8, 12, 16, 20]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [2,3,4]\n",
        "# criterion\n",
        "criterion=['entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "# 11*7*10*10*2 = 15400\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "print(rfc_grid.best_estimator_, '\\n',rfc_grid.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=64, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=2, min_samples_split=8,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.8753026634382567\n",
            "It cost 75.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCnKIF2-uyEh",
        "colab_type": "code",
        "outputId": "f3be241a-5355-410a-a0c5-935acd482332",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='entropy',max_depth=64,min_samples_leaf=2, min_samples_split=20,n_estimators=160)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_test)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_test, y_test),3))\n",
        "print(confusion_matrix(y_test, y_rfc_pred))\n",
        "print(classification_report(y_test, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.875\n",
            "[[162  19]\n",
            " [ 25 146]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88       181\n",
            "           1       0.88      0.85      0.87       171\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       352\n",
            "   macro avg       0.88      0.87      0.87       352\n",
            "weighted avg       0.88      0.88      0.87       352\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "may_o0HwuyEi",
        "colab_type": "code",
        "outputId": "0be7bdfa-bb99-4778-dd8a-b5e301dfc158",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Number of trees in random forest\n",
        "n_estimators = [100,120,140,160]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [32,48,64,80,96]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [8, 16, 20]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1,2,4]\n",
        "# criterion\n",
        "criterion=['gini','entropy']\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'criterion': criterion}\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier()\n",
        "# Random search of parameters, using 5 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "#rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rfc_grid = GridSearchCV(rfc, random_grid)\n",
        "rfc_grid.fit(X_train, y_train)\n",
        "print(rfc_grid.best_estimator_, '\\n',rfc_grid.best_score_)\n",
        "print(\"It cost\", round((time.time()-start),2)) #90s in windows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "            max_depth=96, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=2, min_samples_split=8,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False) \n",
            " 0.8795399515738499\n",
            "It cost 157.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyhosz_2uyEj",
        "colab_type": "code",
        "outputId": "abe5f6e2-cdcf-47c3-cd7e-82ddd77faebc",
        "colab": {}
      },
      "source": [
        "# Random Forest\n",
        "rfc = RandomForestClassifier(criterion='entropy',max_depth=64,min_samples_leaf=2, min_samples_split=8,n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_rfc_pred = rfc.predict(X_valid)\n",
        "print(\"The Random Forest accuracy classification score is\", round(rfc.score(X_valid, y_valid),3))\n",
        "print(confusion_matrix(y_valid, y_rfc_pred))\n",
        "print(classification_report(y_valid, y_rfc_pred, target_names=[\"0\", \"1\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Random Forest accuracy classification score is 0.88\n",
            "[[147  15]\n",
            " [ 25 145]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       162\n",
            "           1       0.91      0.85      0.88       170\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       332\n",
            "   macro avg       0.88      0.88      0.88       332\n",
            "weighted avg       0.88      0.88      0.88       332\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcMLtXg-uyEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TOmEUz9uyEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knhLd0wuyEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV5nhWVmuyEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGlyLhuguyEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1knKCvfuyEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IecPowcquyEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tse1uskduyEy",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8\n",
        "\n",
        "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "\n",
        "https://stackoverflow.com/questions/30102973/how-to-get-best-estimator-on-gridsearchcv-random-forest-classifier-scikit\n",
        "\n",
        "https://medium.com/@aneesha/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_h7XETKuyEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "with open('dict.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in gridsearch_rbf_lin.cv_results_.items():\n",
        "       writer.writerow([key, value])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}